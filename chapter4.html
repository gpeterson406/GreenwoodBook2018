<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Two-Way ANOVA | Intermediate Statistics with R</title>
  <meta name="description" content="Chapter 4 Two-Way ANOVA | Intermediate Statistics with R" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Two-Way ANOVA | Intermediate Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="gpeterson406/Greenwood_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Two-Way ANOVA | Intermediate Statistics with R" />
  
  
  

<meta name="author" content="Mark C Greenwood" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter3.html">
<link rel="next" href="chapter5.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intermediate Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#section1-5"><i class="fa fa-check"></i><b>1.1</b> Summary of important R code</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> (R)e-Introduction to statistics</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#section2-3"><i class="fa fa-check"></i><b>2.1</b> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#section2-4"><i class="fa fa-check"></i><b>2.2</b> Permutation testing for the two sample mean situation</a></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#section2-5"><i class="fa fa-check"></i><b>2.3</b> Hypothesis testing (general)</a></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#section2-6"><i class="fa fa-check"></i><b>2.4</b> Connecting randomization (nonparametric) and parametric tests</a></li>
<li class="chapter" data-level="2.5" data-path="chapter2.html"><a href="chapter2.html#section2-7"><i class="fa fa-check"></i><b>2.5</b> Second example of permutation tests</a></li>
<li class="chapter" data-level="2.6" data-path="chapter2.html"><a href="chapter2.html#section2-8"><i class="fa fa-check"></i><b>2.6</b> Confidence intervals and bootstrapping</a></li>
<li class="chapter" data-level="2.7" data-path="chapter2.html"><a href="chapter2.html#section2-9"><i class="fa fa-check"></i><b>2.7</b> Bootstrap confidence intervals for difference in GPAs</a></li>
<li class="chapter" data-level="2.8" data-path="chapter2.html"><a href="chapter2.html#section2-10"><i class="fa fa-check"></i><b>2.8</b> Chapter summary</a></li>
<li class="chapter" data-level="2.9" data-path="chapter2.html"><a href="chapter2.html#section2-11"><i class="fa fa-check"></i><b>2.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="2.10" data-path="chapter2.html"><a href="chapter2.html#section2-12"><i class="fa fa-check"></i><b>2.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> One-Way ANOVA</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#section3-1"><i class="fa fa-check"></i><b>3.1</b> Situation</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#section3-2"><i class="fa fa-check"></i><b>3.2</b> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#section3-3"><i class="fa fa-check"></i><b>3.3</b> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#section3-4"><i class="fa fa-check"></i><b>3.4</b> ANOVA model diagnostics including QQ-plots</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#section3-5"><i class="fa fa-check"></i><b>3.5</b> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#section3-6"><i class="fa fa-check"></i><b>3.6</b> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li class="chapter" data-level="3.7" data-path="chapter3.html"><a href="chapter3.html#section3-7"><i class="fa fa-check"></i><b>3.7</b> Pair-wise comparisons for Prisoner Rating data</a></li>
<li class="chapter" data-level="3.8" data-path="chapter3.html"><a href="chapter3.html#section3-8"><i class="fa fa-check"></i><b>3.8</b> Chapter summary</a></li>
<li class="chapter" data-level="3.9" data-path="chapter3.html"><a href="chapter3.html#section3-9"><i class="fa fa-check"></i><b>3.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="3.10" data-path="chapter3.html"><a href="chapter3.html#section3-10"><i class="fa fa-check"></i><b>3.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Two-Way ANOVA</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#section4-1"><i class="fa fa-check"></i><b>4.1</b> Situation</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#section4-2"><i class="fa fa-check"></i><b>4.2</b> Designing a two-way experiment and visualizing results</a></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#section4-3"><i class="fa fa-check"></i><b>4.3</b> Two-Way ANOVA models and hypothesis tests</a></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#section4-4"><i class="fa fa-check"></i><b>4.4</b> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li class="chapter" data-level="4.5" data-path="chapter4.html"><a href="chapter4.html#section4-5"><i class="fa fa-check"></i><b>4.5</b> Observational study example: The Psychology of Debt</a></li>
<li class="chapter" data-level="4.6" data-path="chapter4.html"><a href="chapter4.html#section4-6"><i class="fa fa-check"></i><b>4.6</b> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li class="chapter" data-level="4.7" data-path="chapter4.html"><a href="chapter4.html#section4-7"><i class="fa fa-check"></i><b>4.7</b> Chapter summary</a></li>
<li class="chapter" data-level="4.8" data-path="chapter4.html"><a href="chapter4.html#section4-8"><i class="fa fa-check"></i><b>4.8</b> Summary of important R code</a></li>
<li class="chapter" data-level="4.9" data-path="chapter4.html"><a href="chapter4.html#section4-9"><i class="fa fa-check"></i><b>4.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Chi-square tests</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#section5-1"><i class="fa fa-check"></i><b>5.1</b> Situation, contingency tables, and tableplots</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#section5-2"><i class="fa fa-check"></i><b>5.2</b> Homogeneity test hypotheses</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#section5-3"><i class="fa fa-check"></i><b>5.3</b> Independence test hypotheses</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#section5-4"><i class="fa fa-check"></i><b>5.4</b> Models for R by C tables</a></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#section5-5"><i class="fa fa-check"></i><b>5.5</b> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#section5-6"><i class="fa fa-check"></i><b>5.6</b> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#section5-7"><i class="fa fa-check"></i><b>5.7</b> Examining residuals for the source of differences</a></li>
<li class="chapter" data-level="5.8" data-path="chapter5.html"><a href="chapter5.html#section5-8"><i class="fa fa-check"></i><b>5.8</b> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li class="chapter" data-level="5.9" data-path="chapter5.html"><a href="chapter5.html#section5-9"><i class="fa fa-check"></i><b>5.9</b> Political party and voting results: Complete analysis</a></li>
<li class="chapter" data-level="5.10" data-path="chapter5.html"><a href="chapter5.html#section5-10"><i class="fa fa-check"></i><b>5.10</b> Is cheating and lying related in students?</a></li>
<li class="chapter" data-level="5.11" data-path="chapter5.html"><a href="chapter5.html#section5-11"><i class="fa fa-check"></i><b>5.11</b> Analyzing a stratified random sample of California schools</a></li>
<li class="chapter" data-level="5.12" data-path="chapter5.html"><a href="chapter5.html#section5-12"><i class="fa fa-check"></i><b>5.12</b> Chapter summary</a></li>
<li class="chapter" data-level="5.13" data-path="chapter5.html"><a href="chapter5.html#section5-13"><i class="fa fa-check"></i><b>5.13</b> Summary of important R commands</a></li>
<li class="chapter" data-level="5.14" data-path="chapter5.html"><a href="chapter5.html#section5-14"><i class="fa fa-check"></i><b>5.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Correlation and Simple Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#section6-1"><i class="fa fa-check"></i><b>6.1</b> Relationships between two quantitative variables</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#section6-2"><i class="fa fa-check"></i><b>6.2</b> Estimating the correlation coefficient</a></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#section6-3"><i class="fa fa-check"></i><b>6.3</b> Relationships between variables by groups</a></li>
<li class="chapter" data-level="6.4" data-path="chapter6.html"><a href="chapter6.html#section6-4"><i class="fa fa-check"></i><b>6.4</b> Inference for the correlation coefficient (Optional section)</a></li>
<li class="chapter" data-level="6.5" data-path="chapter6.html"><a href="chapter6.html#section6-5"><i class="fa fa-check"></i><b>6.5</b> Are tree diameters related to tree heights?</a></li>
<li class="chapter" data-level="6.6" data-path="chapter6.html"><a href="chapter6.html#section6-6"><i class="fa fa-check"></i><b>6.6</b> Describing relationships with a regression model</a></li>
<li class="chapter" data-level="6.7" data-path="chapter6.html"><a href="chapter6.html#section6-7"><i class="fa fa-check"></i><b>6.7</b> Least Squares Estimation</a></li>
<li class="chapter" data-level="6.8" data-path="chapter6.html"><a href="chapter6.html#section6-8"><i class="fa fa-check"></i><b>6.8</b> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li class="chapter" data-level="6.9" data-path="chapter6.html"><a href="chapter6.html#section6-9"><i class="fa fa-check"></i><b>6.9</b> Outliers: leverage and influence</a></li>
<li class="chapter" data-level="6.10" data-path="chapter6.html"><a href="chapter6.html#section6-10"><i class="fa fa-check"></i><b>6.10</b> Residual diagnostics – setting the stage for inference</a></li>
<li class="chapter" data-level="6.11" data-path="chapter6.html"><a href="chapter6.html#section6-11"><i class="fa fa-check"></i><b>6.11</b> Old Faithful discharge and waiting times</a></li>
<li class="chapter" data-level="6.12" data-path="chapter6.html"><a href="chapter6.html#section6-12"><i class="fa fa-check"></i><b>6.12</b> Chapter summary</a></li>
<li class="chapter" data-level="6.13" data-path="chapter6.html"><a href="chapter6.html#section6-13"><i class="fa fa-check"></i><b>6.13</b> Summary of important R code</a></li>
<li class="chapter" data-level="6.14" data-path="chapter6.html"><a href="chapter6.html#section6-14"><i class="fa fa-check"></i><b>6.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Simple linear regression inference</a><ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#section7-1"><i class="fa fa-check"></i><b>7.1</b> Model</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#section7-2"><i class="fa fa-check"></i><b>7.2</b> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#section7-3"><i class="fa fa-check"></i><b>7.3</b> Bozeman temperature trend</a></li>
<li class="chapter" data-level="7.4" data-path="chapter7.html"><a href="chapter7.html#section7-4"><i class="fa fa-check"></i><b>7.4</b> Randomizing inferences for the slope coefficient</a></li>
<li class="chapter" data-level="7.5" data-path="chapter7.html"><a href="chapter7.html#section7-5"><i class="fa fa-check"></i><b>7.5</b> Transformations part I: Linearizing relationships</a></li>
<li class="chapter" data-level="7.6" data-path="chapter7.html"><a href="chapter7.html#section7-6"><i class="fa fa-check"></i><b>7.6</b> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li class="chapter" data-level="7.7" data-path="chapter7.html"><a href="chapter7.html#section7-7"><i class="fa fa-check"></i><b>7.7</b> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li class="chapter" data-level="7.8" data-path="chapter7.html"><a href="chapter7.html#section7-8"><i class="fa fa-check"></i><b>7.8</b> Chapter summary</a></li>
<li class="chapter" data-level="7.9" data-path="chapter7.html"><a href="chapter7.html#section7-9"><i class="fa fa-check"></i><b>7.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="7.10" data-path="chapter7.html"><a href="chapter7.html#section7-10"><i class="fa fa-check"></i><b>7.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#section8-1"><i class="fa fa-check"></i><b>8.1</b> Going from SLR to MLR</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#section8-2"><i class="fa fa-check"></i><b>8.2</b> Validity conditions in MLR</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#section8-3"><i class="fa fa-check"></i><b>8.3</b> Interpretation of MLR terms</a></li>
<li class="chapter" data-level="8.4" data-path="chapter8.html"><a href="chapter8.html#section8-4"><i class="fa fa-check"></i><b>8.4</b> Comparing multiple regression models</a></li>
<li class="chapter" data-level="8.5" data-path="chapter8.html"><a href="chapter8.html#section8-5"><i class="fa fa-check"></i><b>8.5</b> General recommendations for MLR interpretations and VIFs</a></li>
<li class="chapter" data-level="8.6" data-path="chapter8.html"><a href="chapter8.html#section8-6"><i class="fa fa-check"></i><b>8.6</b> MLR inference: Parameter inferences using the t-distribution</a></li>
<li class="chapter" data-level="8.7" data-path="chapter8.html"><a href="chapter8.html#section8-7"><i class="fa fa-check"></i><b>8.7</b> Overall F-test in multiple linear regression</a></li>
<li class="chapter" data-level="8.8" data-path="chapter8.html"><a href="chapter8.html#section8-8"><i class="fa fa-check"></i><b>8.8</b> Case study: First year college GPA and SATs</a></li>
<li class="chapter" data-level="8.9" data-path="chapter8.html"><a href="chapter8.html#section8-9"><i class="fa fa-check"></i><b>8.9</b> Different intercepts for different groups: MLR with indicator variables</a></li>
<li class="chapter" data-level="8.10" data-path="chapter8.html"><a href="chapter8.html#section8-10"><i class="fa fa-check"></i><b>8.10</b> Additive MLR with more than two groups: Headache example</a></li>
<li class="chapter" data-level="8.11" data-path="chapter8.html"><a href="chapter8.html#section8-11"><i class="fa fa-check"></i><b>8.11</b> Different slopes and different intercepts</a></li>
<li class="chapter" data-level="8.12" data-path="chapter8.html"><a href="chapter8.html#section8-12"><i class="fa fa-check"></i><b>8.12</b> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li class="chapter" data-level="8.13" data-path="chapter8.html"><a href="chapter8.html#section8-13"><i class="fa fa-check"></i><b>8.13</b> AICs for model selection</a></li>
<li class="chapter" data-level="8.14" data-path="chapter8.html"><a href="chapter8.html#section8-14"><i class="fa fa-check"></i><b>8.14</b> Case study: Forced expiratory volume model selection using AICs</a></li>
<li class="chapter" data-level="8.15" data-path="chapter8.html"><a href="chapter8.html#section8-15"><i class="fa fa-check"></i><b>8.15</b> Chapter summary</a></li>
<li class="chapter" data-level="8.16" data-path="chapter8.html"><a href="chapter8.html#section8-16"><i class="fa fa-check"></i><b>8.16</b> Summary of important R code</a></li>
<li class="chapter" data-level="8.17" data-path="chapter8.html"><a href="chapter8.html#section8-17"><i class="fa fa-check"></i><b>8.17</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Case studies</a><ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#section9-1"><i class="fa fa-check"></i><b>9.1</b> Overview of material covered</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#section9-2"><i class="fa fa-check"></i><b>9.2</b> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li class="chapter" data-level="9.3" data-path="chapter9.html"><a href="chapter9.html#section9-3"><i class="fa fa-check"></i><b>9.3</b> Ants learn to rely on more informative attributes during decision-making</a></li>
<li class="chapter" data-level="9.4" data-path="chapter9.html"><a href="chapter9.html#section9-4"><i class="fa fa-check"></i><b>9.4</b> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li class="chapter" data-level="9.5" data-path="chapter9.html"><a href="chapter9.html#section9-5"><i class="fa fa-check"></i><b>9.5</b> What do didgeridoos really do about sleepiness?</a></li>
<li class="chapter" data-level="9.6" data-path="chapter9.html"><a href="chapter9.html#section9-6"><i class="fa fa-check"></i><b>9.6</b> General summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Intermediate Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter4" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Two-Way ANOVA</h1>
<div id="section4-1" class="section level2">
<h2><span class="header-section-number">4.1</span> Situation</h2>
<p>In this chapter, we extend the One-Way ANOVA to situations with two factors or categorical explanatory
variables in a method that is generally called the <strong><em>Two-Way ANOVA</em></strong>.

This
allows researchers to simultaneously study two variables that might
explain variability in the responses and explore whether the impacts of one
variable change depending on the level of the other explanatory variable. In some situations, each
observation is so expensive that researchers want to use a single study to
explore two different sets of research questions in the same round of data
collection. For example, a company might want to study factors that affect the
number of defective products per day and are interested in the impacts of two
different types of training programs and three different levels of production
quotas. These methods would allow engineers to compare the training programs,
production quotas, and see if the training programs work differently for
different production quotas. In a clinical trials context, it is well known
that certain factors can change the performance of certain drugs. For example,
different dosages of a drug might have different benefits or side-effects on
men, versus women or children. <strong>When the impact of one factor on the response changes depending on the
level of another factor</strong>, we say that the two explanatory variables <strong><em>interact</em></strong>.

It is also possible
for both factors to be related to differences in the mean responses and not
interact. For example, suppose there is a difference in the
response means between men and women and a difference among various dosages,
but the effect of increasing the dosage is the same for the male and female
subjects. This is an example of what is called an <strong><em>additive</em></strong> type of model.
In general, the world is more complicated than the single factor models we
considered in Chapter <a href="chapter3.html#chapter3">3</a> can account for, especially in
observational studies, so these models allow us to start to handle more
realistic situations.
</p>
<p>Consider the following “experiment” where we want to compare the strength of
different brands of paper towels when they are wet. The response variable
will be the time to failure in seconds (a continuous response variable) when
a weight is placed on the towel held at the four corners. We are interested
in studying the differences between brands and the impact of different amounts
of water applied to the towels.</p>
<ul>
<li><p>Predictors (Explanatory Variables): <strong>A</strong>: <code>Brand</code> (2 brands of interest,
named <em>B1</em> and <em>B2</em>) and <strong>B</strong>: Number of <code>Drops</code> of water (10, 20, 30 drops).</p></li>
<li><p>Response: <em>Time</em> to failure (in seconds) of a towel (<span class="math inline">\(y\)</span>) with a weight
sitting in the middle of the towel.</p></li>
</ul>
</div>
<div id="section4-2" class="section level2">
<h2><span class="header-section-number">4.2</span> Designing a two-way experiment and visualizing results</h2>
<p>Ideally, we want to randomly assign the levels of each factor so that we can
attribute causality to any detected effects and to reduce the chances of
<em>confounding</em>.


Because there are two factors, we would need to design a random
assignment scheme to select the levels of both variables. For example, we could
randomly select a brand and then randomly select the number of drops to apply
from the levels chosen for each measurement. Or we could decide on how many
observations we want at each combination of the two factors (ideally having
them all equal so the design is <strong><em>balanced</em></strong>) and then randomize the order
of applying the different combinations of levels.
</p>
<p>Why might it be important to randomly apply the brand and number of drops in
an experiment? There are situations where the order of observations can be
related to changes in the responses and we want to be able to eliminate
the order of observations from being related to the levels of the factors – otherwise the order of observations and levels of the factors would be <em>confounded</em>.
For example, suppose that the area where the experiment is being performed
becomes wet over time and the later measurements have extra water that gets
onto the paper towels and they tend to fail more quickly. If all the observations
for the second brand were done later in the study, then the <em>order of observations</em>
impacts could make the second brand look worse. If the order of measurements to be made is
randomized, then even if there is some drift in the responses over the order
of observations it should still be possible to see the differences in the
randomly assigned effects. If the study incorporates repeated measurements on
human subjects, randomizing the order of treatments they are exposed to can
alleviate impacts of them “learning” through the study, something that we
would not have to worry about with paper towels.</p>
<p>In observational studies, we do not have the luxury of random assignment, that
is, we cannot randomly assign levels of the treatment variables to our
subjects, so we cannot guarantee that the only difference between the groups
are based on the differences in the explanatory variables.

As discussed before, because we can’t control
which level of the variables are assigned to the subjects, we cannot make
causal inferences and have to worry about other variables being the real
drivers of the results. Although we can never establish causal inference
with observational studies, we can generalize our results to a larger
population if we have a representative (ideally fully random) sample from our population of interest.</p>
<p>It is also possible that we might have studies where some of the variables are
randomly assigned and others that are not randomly assignable. The most common
versions of this are what we sometimes call subject “demographics”, such as
sex, income, race, etc. We might be performing a study where we can randomly
assign treatments to these subjects but might also want to account for
differences based on income level, which we can’t assign. In these cases, the
scope of inference gets complicated – differences seen on randomized variables
can be causally interpreted but you have to be careful to not say that the
demographics caused differences. Suppose that a randomly assigned drug dosage
is found to show differences in male patients but not in female patients. We
could say that the dosage causes differences in males but does not in females.
We are not saying that sex caused the differences but that the causal
differences were modified by the sex of the subjects.
</p>
<p>Even when we do have random assignment of treatments it is important to think
about who/what is included in the sample. To get back to the paper towel
example, we are probably interested in more than the sheets of the rolls
we have to work with. If we could randomly select the studied paper towels
from all paper towels made by each brand, our conclusions could be extended
to those populations. That probably would not be practical, but trying to
make sure that the towels are representative of all made by each brand by
checking for defects and maybe picking towels from a few different rolls
would be a good start to being able to extend inferences beyond the tested
towels. If you were doing this in the factory, it might be possible to randomly sample from the towels produced.</p>
<p>Once random assignment and random sampling is settled, the final aspect of
study design involves deciding on the number of observations that should be
made. The short (glib) answer is to take as many as you can afford. With more
observations comes higher power to detect differences if they exist, which
is a desired attribute of all studies.

It is also important to make sure that
you obtain multiple observations at each combination of the treatment levels,
which are called <strong><em>replicates</em></strong>.  Having replicate measurements allows
estimation of the mean for each combination of the treatment levels as well
as estimation and testing for an interaction.

And we always prefer having
balanced designs because they provide resistance to violation of some
assumptions as noted in Chapter <a href="chapter3.html#chapter3">3</a>. A <strong><em>balanced design</em></strong>
in a Two-Way ANOVA setting involves having the same sample size for every
combination of the levels of the treatments.
</p>
<p>With two categorical explanatory variables, there are now five possible
scenarios for the truth. Different situations are created depending on
whether there is an interaction between the two variables,
whether both variables are important but do not interact, or whether either of the
variables matter at all.

Basically, there are five different possible outcomes
in a randomized Two-Way ANOVA study, listed in order of increasing model
complexity:</p>
<ol style="list-style-type: decimal">
<li><p>Neither A or B has an effect on the responses (nothing causes differences
in responses).</p></li>
<li><p>A has an effect, B does not (only A causes differences in responses).</p></li>
<li><p>B has an effect, A does not (only B causes differences in responses).</p></li>
<li><p>Both A and B have effects on response but no interaction (A and B both
cause differences in responses but the impacts are <em>additive</em>).</p></li>
<li><p>Effect of A on response differs based on the levels of B, the opposite is also true
(means for levels of response across A are different for different levels of B, or, simply,
A and B interact in their effect on the response).</p></li>
</ol>
<p>To illustrate these five potential outcomes, we will consider a fake version of
the paper towel example. It ended up being really messy and complicated to
actually perform the experiment as we described it so these data were simulated. The hope is to use this simple example to illustrate some of the Two-Way ANOVA possibilities. The first step is to understand what has been observed (number
observations at each combination of factors) and look at some summary
statistics across all the “groups”. The data set is available via the following link:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(readr)
pt &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/pt.csv&quot;</span>)
pt<span class="op">$</span>drops &lt;-<span class="st"> </span><span class="kw">factor</span>(pt<span class="op">$</span>drops)
pt<span class="op">$</span>brand &lt;-<span class="st"> </span><span class="kw">factor</span>(pt<span class="op">$</span>brand)</code></pre>
<p>The data set contains five observations per combination of treatment levels as
provided by the <code>tally</code> function. To get counts for combinations of the
variables, use the general formula of <code>tally(x1~x2, data=...)</code> – noting that the order of <code>x1</code> and <code>x2</code> doesn’t matter here:
</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(mosaic)
<span class="kw">tally</span>(brand<span class="op">~</span>drops, <span class="dt">data=</span>pt)</code></pre>
<pre><code>##      drops
## brand 10 20 30
##    B1  5  5  5
##    B2  5  5  5</code></pre>
<p>The sample sizes in each of the six treatment level combinations of <code>Brand</code>
and <code>Drops</code> [(<em>B1</em>, 10), (<em>B1</em>, 20), (<em>B1</em>, 30), (<em>B2</em>, 10), (<em>B2</em>, 20),
(<em>B2</em>, 30)] are <span class="math inline">\(n_{jk} = 5\)</span> for <span class="math inline">\(j^{th}\)</span> level of <code>Brand</code> (<span class="math inline">\(j=1, 2\)</span>) and
<span class="math inline">\(k^{th}\)</span> level of <code>Drops</code> (<span class="math inline">\(k=1, 2, 3\)</span>). The <code>tally</code> function gives us a
<strong><em>contingency table</em></strong> with <span class="math inline">\(R = 2\)</span> rows (<em>B1</em>, <em>B2</em>) and <span class="math inline">\(C = 3\)</span> columns
(10, 20, and 30).

We’ll have more fun with <span class="math inline">\(R\)</span> by <span class="math inline">\(C\)</span>
tables in Chapter <a href="chapter5.html#chapter5">5</a> – here it helps us to see the sample size in
each combination of factor levels. The <code>favstats</code> function also helps us
dig into the results for all combinations of factor levels. The notation
involves putting both variables after the “~” with a “<code>+</code>” between them.
In the output, the first row contains summary information for the
5 observations for <code>Brand</code> <em>B1</em> and <code>Drops</code> amount 10. It also contains the
sample size in the <code>n</code> column, although here it rolled into a new set of
rows with the standard deviations of each combination.</p>

<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">favstats</span>(responses<span class="op">~</span>brand<span class="op">+</span>drops, <span class="dt">data=</span>pt)</code></pre>
<pre><code>##   brand.drops       min        Q1   median       Q3      max     mean
## 1       B1.10 0.3892621 1.3158737 1.906436 2.050363 2.333138 1.599015
## 2       B2.10 2.3078095 2.8556961 3.001147 3.043846 3.050417 2.851783
## 3       B1.20 0.3838299 0.7737965 1.516424 1.808725 2.105380 1.317631
## 4       B2.20 1.1415868 1.9382142 2.066681 2.838412 3.001200 2.197219
## 5       B1.30 0.2387500 0.9804284 1.226804 1.555707 1.829617 1.166261
## 6       B2.30 0.5470565 1.1205102 1.284117 1.511692 2.106356 1.313946
##          sd n missing
## 1 0.7714970 5       0
## 2 0.3140764 5       0
## 3 0.7191978 5       0
## 4 0.7509989 5       0
## 5 0.6103657 5       0
## 6 0.5686485 5       0</code></pre>
<p>The next step is to visually explore the results across the combinations of the two explanatory variables. The beanplot can be extended to handle these
sorts of two-way situations only if one of the two variables is a two-level
variable.

This is a pretty serious constraint on this display, so we will
show you the plot (Figure <a href="chapter4.html#fig:Figure4-1">4.1</a>) but not focus on the code.
The reason beanplots can only handle <span class="math inline">\(2 \times K\)</span> designs is that the
beans are split along a vertical line for each of the <span class="math inline">\(K\)</span> levels of the other variable.
In Figure <a href="chapter4.html#fig:Figure4-1">4.1</a>, the <code>Brand</code> B1 density curves are shaded and the
B2 curves are not. In reading these plots, look for differences in each level
and whether those differences change across the levels of the other variable.
Specifically, start with comparing the two brands for different amounts of water.
Do the brands seem different? Certainly for 10 drops of water the two look
different but not for 30 drops. We can also look for combinations of factors
that produce the highest or lowest responses in this display. It appears that
the time to failure is highest in the low water drop groups but as the water
levels increase, the time to failure falls and the differences in the two
brands seem to decrease. The fake data seem to have relatively similar
amounts of variability and distribution shapes – remembering that there are
only 5 observations available for describing the shape of responses for each
combination. These data were simulated using a normal distribution and
constant variance if that gives you some extra confidence in assessing these
model assumptions.</p>
<p>(ref:fig4-1) Beanplot of paper towel data by <code>Drops</code> (x-axis) and <code>Brand</code>
(side of bean, shaded area for <code>Brand</code> <em>B1</em>).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(beanplot)
<span class="kw">beanplot</span>(responses<span class="op">~</span>brand<span class="op">*</span>drops, <span class="dt">data=</span>pt, <span class="dt">side=</span><span class="st">&quot;b&quot;</span>, 
         <span class="dt">col=</span><span class="kw">list</span>(<span class="st">&quot;lightblue&quot;</span>,<span class="st">&quot;white&quot;</span>), <span class="dt">xlab=</span><span class="st">&quot;Drops&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Time&quot;</span>, 
         <span class="dt">method=</span><span class="st">&quot;jitter&quot;</span>, <span class="dt">log=</span><span class="st">&quot;&quot;</span>)
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;B1&quot;</span>,<span class="st">&quot;B2&quot;</span>), <span class="dt">fill=</span><span class="kw">c</span>(<span class="st">&quot;lightblue&quot;</span>,<span class="st">&quot;white&quot;</span>))</code></pre>
<div class="figure"><span id="fig:Figure4-1"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-1-1.png" alt="(ref:fig4-1)" width="480" />
<p class="caption">
Figure 4.1: (ref:fig4-1)
</p>
</div>
<p>The beanplots can’t handle situations where both variables have more than two
levels – we need a simpler display that just focuses on the means at the
combinations of the two explanatory variables. The means for each combination
of levels that you can find in the <code>favstats</code> output are more usefully used
in what is called an <strong><em>interaction plot</em></strong>.

Interaction plots display the mean
responses (y-axis) versus levels of one predictor variable on the x-axis,
adding points and separate lines for each level of the other predictor variable. Because
we don’t like any of the available functions in R, we wrote our own function,
called <code>intplot</code> that you can download using:
</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/intplotfunctions.R&quot;</span>)</code></pre>
<p>The function allows a formula interface like <code>Y~X1*X2</code> and provides the
means <span class="math inline">\(\pm\)</span> 1 SE (vertical bars) and adds a legend to help make
everything clear.</p>

<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">intplot</span>(responses<span class="op">~</span>brand<span class="op">*</span>drops, <span class="dt">data=</span>pt)</code></pre>
<div class="figure"><span id="fig:Figure4-2"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-2-1.png" alt="Interaction plot of the paper towel data with Drops on the x-axis and different lines based on Brand." width="960" />
<p class="caption">
Figure 4.2: Interaction plot of the paper towel data with <code>Drops</code> on the x-axis and different lines based on <code>Brand</code>.
</p>
</div>
<p>Interaction plots can always be made two different ways by switching the order
of the variables. Figure <a href="chapter4.html#fig:Figure4-2">4.2</a> contains <code>Drops</code> on the x-axis
and Figure <a href="chapter4.html#fig:Figure4-3">4.3</a> has <code>Brand</code> on the x-axis. Typically putting
the variable with more levels on the x-axis will make interpretation easier,
but not always. Try both and decide on the one that you like best.
</p>

<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">intplot</span>(responses<span class="op">~</span>drops<span class="op">*</span>brand, <span class="dt">data=</span>pt)</code></pre>
<div class="figure"><span id="fig:Figure4-3"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-3-1.png" alt="Interaction plot of paper towel data with Brand on the x-axis and lines based on Drops." width="960" />
<p class="caption">
Figure 4.3: Interaction plot of paper towel data with <code>Brand</code> on the x-axis and lines based on <code>Drops</code>.
</p>
</div>
<p>The formula in this function builds on our previous notation and now we include
both predictor variables with an “<code>*</code>” between them. Using an asterisk between
explanatory variables is one way of telling R to include an interaction between
the variables. While the interaction may or may not be present, the interaction
plot helps us to explore those potential differences.</p>
<p>There are a variety of aspects of the interaction plots to pay attention to.

Initially, the question to answer is whether it appears that there is an
interaction between the predictor variables.

When there is an interaction, you
will see <strong><em>non-parallel lines</em></strong> in the interaction plot.

You want to look from
left to right in the plot and assess whether the lines are close to parallel,
relative to the amount of variability in the means. If it seems that there is
clear visual evidence of non-parallel lines, then the interaction is likely
worth considering (we will typically use a hypothesis test to formally assess
this – see discussion below). If the lines look to be close to parallel, then
there probably isn’t an interaction between
the variables. Without an interaction present, that means that the differences
in the response across levels of one variable doesn’t change based on the levels of the other
variable and vice-versa. This means that we can consider the <strong><em>main effects</em></strong>
of each variable on their own<a href="#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a>.


Main effects are much like the results we found in
Chapter <a href="chapter3.html#chapter3">3</a> where we can compare
means across levels of a single variable except that there are results for two
variables to extract from the model. With the presence of an interaction, it is
complicated to summarize how each variable is affecting the response variable
because their impacts change depending on the level of the other factor. And
plots like the interaction plot provide us with useful information.</p>
<p>If the lines are not parallel, then
focus in on comparing the levels of one variable as the other variable changes.
Remember that the definition of an interaction is that the differences among
levels of one variable depends on the level of the other variable being
considered. “Visually” this means comparing the size of the differences in the
lines from left to right. In Figures <a href="chapter4.html#fig:Figure4-2">4.2</a> and <a href="chapter4.html#fig:Figure4-3">4.3</a>,
the effect of amount of water
changes based on the brand being considered. In Figure <a href="chapter4.html#fig:Figure4-3">4.3</a>,
the three lines
represent the three water levels. The difference between the brands (left to
right, <em>B1</em> to <em>B2</em>) is different depending on how much water was present. It
appears that <code>Brand</code> <em>B2</em> lasted longer at the lower water levels but that the
difference between the two brands dropped as the water levels increased. The
same story appears in Figure <a href="chapter4.html#fig:Figure4-2">4.2</a>. As the
water levels increase (left to right, 10 to 20 to 30 drops), the differences
between the two brands decrease. Of the two versions, Figure <a href="chapter4.html#fig:Figure4-2">4.2</a>
is probably easier to read here. Sometimes it is nice to see the interaction plot made both ways simultaneously, so you can also use the <code>intplotarray</code> function, which provides Figure <a href="chapter4.html#fig:Figure4-4">4.4</a>. This plot also adds beanplots to the off-diagonals so you can explore the main effects of each variable, if that is reasonable.

 The interaction plots can able to be used to
identify the best and worst mean responses for combinations of the treatment
levels. For example, 10 <code>Drops</code> and <code>Brand</code> <em>B2</em> lasts longest, on average, and 30 <code>Drops</code> with <code>Brand</code> <em>B1</em> fails fastest, on average. In any version of the plot here, the lines do not appear to be parallel suggesting that further exploration of the
interaction appears to be warranted.</p>

<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">intplotarray</span>(responses<span class="op">~</span>drops<span class="op">*</span>brand, <span class="dt">data=</span>pt)</code></pre>
<div class="figure"><span id="fig:Figure4-4"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-4-1.png" alt="Interaction plot array of paper towel data with two different versions of interaction plots and beanplots of the responses versus each explanatory variable." width="960" />
<p class="caption">
Figure 4.4: Interaction plot array of paper towel data with two different versions of interaction plots and beanplots of the responses versus each explanatory variable.
</p>
</div>
<p>Before we get to the hypothesis tests
to formally make this assessment (you knew some sort of p-value was coming, right?),
we can visualize the 5 different scenarios that could characterize the sorts of
results you could observe in a Two-Way ANOVA situation. Figure <a href="chapter4.html#fig:Figure4-5">4.5</a>
shows 4 of the 5 scenarios. In panel (a), when there are no differences from either
variable (Scenario 1), it provides relatively parallel lines and basically no
differences either across <code>Drops</code> levels (x-axis) or <code>Brand</code> (lines). This would
result in little to no evidence related to a difference in brands, water
levels, or any interaction between them.</p>

<div class="figure"><span id="fig:Figure4-5"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-5-1.png" alt="Interaction plots of four possible scenarios in the paper towel study." width="624" />
<p class="caption">
Figure 4.5: Interaction plots of four possible scenarios in the paper towel study.
</p>
</div>
<p>Scenario 2 (Figure <a href="chapter4.html#fig:Figure4-5">4.5</a> panel (b))
incorporates differences based on factor A (here that is <code>Brand</code>) but no real
difference based on the <code>Drops</code> or any interaction. This results in a clear shift between the lines for the means of the <code>Brands</code> but little to no changes in the level of those lines across water levels.
These lines are relatively parallel. We can see that <code>Brand</code> <em>B2</em> is better than
<code>Brand</code> <em>B1</em> but that is all we can show with these sorts of results.</p>
<p>Scenario 3 (Figure <a href="chapter4.html#fig:Figure4-5">4.5</a> panel (c)) flips the important variable
to B (<code>Drops</code>)
and shows decreasing average times as the water levels increase. Again, the
interaction panels show near parallel-ness in the lines and really just show differences
among the levels of the water. In both Scenarios 2 and 3, we could use a single
variable and drop the other from the model, getting back to a One-Way ANOVA
model, without losing any important information.</p>
<p>Scenario 4 (Figure <a href="chapter4.html#fig:Figure4-5">4.5</a> panel (d)) incorporates
effects of A and B, but they are <strong><em>additive</em></strong>. That means that the effect
of one variable is the same across the levels of the other variable. In this
experiment, that would mean that <code>Drops</code> has the same impact on performance
regardless of brand and that the brands differ but each type of difference is
the same regardless of levels of the other variable.
The interaction plot lines are more or less parallel but now the brands are
clearly different from each other. The plot shows the decrease in performance
based on increasing water levels and that <code>Brand</code> <em>B2</em> is better than
<code>Brand</code> <em>B1</em>. Additive effects show the same difference in lines from left to
right in the interaction plots.</p>
<p>Finally, Scenario 5 (Figure <a href="chapter4.html#fig:Figure4-6">4.6</a>) involves
an interaction between the two variables (<code>Drops</code> and <code>Brand</code>). There are many ways
that interactions can present but the main thing is to look for clearly
non-parallel lines.

As noted in the previous discussion, the <code>Drops</code> effect
appears to change depending on which level of <code>Brand</code> is being considered.
Note that the plot here described as Scenario 5 is the same as the initial plot
of the results in Figure <a href="chapter4.html#fig:Figure4-2">4.2</a>.</p>
<p>(ref:fig4-6) Interaction plot of Scenario 5 where it appears that an
interaction is present.</p>
<div class="figure"><span id="fig:Figure4-6"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-6-1.png" alt="(ref:fig4-6)" width="432" />
<p class="caption">
Figure 4.6: (ref:fig4-6)
</p>
</div>
<p>The typical modeling protocol is to start with assuming that Scenario 5 is a possible
description of the results, related to fitting what is called the
<strong><em>interaction model</em></strong>, and then attempt to simplify the model (to the
<strong><em>additive model</em></strong>) if warranted.

We need a hypothesis test to help decide if
the interaction is “real” – if there
is sufficient evidence to prove that there is an interaction. We need a test
because the lines will never be exactly parallel and, just like in the One-Way
ANOVA situation, the amount of variation around the lines impacts the ability
of the model to detect differences, in this case of an interaction.
</p>
</div>
<div id="section4-3" class="section level2">
<h2><span class="header-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</h2>
<p>To assess interactions with two
variables, we need to fully describe models for the additive and interaction
scenarios and then develop a method for assessing evidence of the need for
different aspects of the models. First, we need to define the notation for
these models:</p>
<ul>
<li><p><span class="math inline">\(y_{ijk}\)</span> is the <span class="math inline">\(i^{th}\)</span> response from the group for level <span class="math inline">\(j\)</span> of factor A
and level <span class="math inline">\(k\)</span> of factor B</p>
<ul>
<li><p><span class="math inline">\(j=1,\ldots,J\)</span>     <span class="math inline">\(J\)</span> is the number of levels of A</p></li>
<li><p><span class="math inline">\(k=1,\ldots,K\)</span>     <span class="math inline">\(K\)</span> is the number of levels of B</p></li>
<li><p><span class="math inline">\(i=1,\ldots,n_{jk}\)</span>     <span class="math inline">\(n_{jk}\)</span> is the sample size for level
<span class="math inline">\(j\)</span> of factor A and level <span class="math inline">\(k\)</span> of factor B</p></li>
<li><p><span class="math inline">\(N=\Sigma\Sigma n_{jk}\)</span> is the total sample size (sum of the number of
observations across all <span class="math inline">\(JK\)</span> groups)</p></li>
</ul></li>
</ul>
<p>We need to extend our previous discussion of reference-coded models to develop a
Two-Way ANOVA model. We start with the <strong><em>Two-Way ANOVA interaction model</em></strong>:
</p>
<p><span class="math display">\[y_{ijk} = \alpha + \tau_j + \gamma_k + \omega_{jk} + \varepsilon_{ijk},\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is the baseline group mean (for level 1 of A <strong>and</strong> level 1 of B),
<span class="math inline">\(\tau_j\)</span> is the deviation for the <strong><em>main effect</em></strong> of A from the baseline
for levels <span class="math inline">\(2,\ldots,J\)</span>, <span class="math inline">\(\gamma_k\)</span> (gamma <span class="math inline">\(k\)</span>) is the deviation for the main
effect of B from the baseline for levels <span class="math inline">\(2,\ldots,K\)</span>, and <span class="math inline">\(\omega_{jk}\)</span>
(omega <span class="math inline">\(jk\)</span>) is the adjustment for the <strong><em>interaction effect</em></strong> for level
<span class="math inline">\(j\)</span> of factor A and level <span class="math inline">\(k\)</span> of factor B for <span class="math inline">\(j=1,\ldots,J\)</span> and <span class="math inline">\(k=1,\ldots,K\)</span>.
In this model, <span class="math inline">\(\tau_1\)</span>, <span class="math inline">\(\gamma_1\)</span>, and <span class="math inline">\(\omega_{11}\)</span> are all fixed at 0.
As in Chapter <a href="chapter3.html#chapter3">3</a>, R will choose the baseline categories
alphabetically but now it is choosing a baseline for both variables and so our
detective work will be doubled to sort this out.</p>
<p>If the interaction term is not important, based on the interaction test
presented below, the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> can be dropped from the model
and we get a model that corresponds to Scenario 4
above. Scenario 4 is where there are two main effects but no interaction
between them. The <strong><em>additive Two-Way model</em></strong> is
</p>
<p><span class="math display">\[y_{ijk} = \alpha + \tau_j + \gamma_k + \varepsilon_{ijk},\]</span></p>
<p>where each component is defined as in the interaction model. The difference between
the interaction and additive models is setting all the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span>
to 0 that are present in the interaction model. When we set parameters to 0 in
models it removes them from the model. Setting parameters to 0 is how we will develop
our hypotheses to test for an interaction, by testing whether there is evidence
enough to reject that all <span class="math inline">\(\omega_{jk}\text{&#39;s}=0\)</span>.</p>
<p>The interaction test hypotheses are</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No interaction between A and B on response in population <span class="math inline">\(\Leftrightarrow\)</span> All
<span class="math inline">\(\omega_{jk}\text{&#39;s}=0\)</span>.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Interaction between A and B on response in population <span class="math inline">\(\Leftrightarrow\)</span> At least
one <span class="math inline">\(\omega_{jk}\ne 0\)</span>.</p></li>
</ul>
<p>To perform this test, a new ANOVA <span class="math inline">\(F\)</span>-test is required (presented below) but
there are also hypotheses relating to the main effects of A (<span class="math inline">\(\tau_j\text{&#39;s}\)</span>)
and B (<span class="math inline">\(\gamma_k\text{&#39;s}\)</span>).


If evidence is found to reject the null hypothesis
that no interaction is
present, then it is dangerous to ignore it and test for the main effects
because important main effects can be masked by interactions (examples later).
It is important to note that, by definition, <strong>both variables matter if an
interaction is found to be important</strong> so the main effect tests may not be
very interesting. If the interaction is found
to be important based on the test and retained in the model, you should focus
on the interaction model (also called the <strong><em>full model</em></strong>) in order to
understand and describe the form of the interaction among the variables.

</p>
<p>If the interaction test does not return
a small p-value and you decide that you do not have evidence to suggest that it is needed, it
can be dropped from the model. In this situation, we would re-fit the model and
focus on the results provided by the additive model – performing tests for the
two additive main effects.

For the first, but not last time, we encounter a
model with more than one variable and more than one test of potential interest. In models
with multiple variables at similar levels (here both are main effects), we are
interested in the results for each variable given that the other variable is in
the model. In many situations, including more than one variable in a model
changes the results for the other variable even if those variables do not
interact. The reason for this is more clear in Chapter <a href="chapter8.html#chapter8">8</a> and really only
matters here if we have unbalanced designs, but we need to start adding a short
modifier to our discussions of main effects – they are the results
<em>conditional on</em> or <em>adjusting for</em> or, simply, <em>given</em>, the other variable(s)
in the model. Specifically, the hypotheses for the two main effects are:</p>
<ul>
<li><p>Main effect test for A: </p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No differences in means across levels of A in population,
given B in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\tau_j\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means across levels A in population,
given B in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\tau_j \ne 0\)</span>, in additive model.</p></li>
</ul></li>
<li><p>Main effect test for B:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No differences in means across levels of B in population,
given A in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\gamma_k\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means across levels B in population,
given A in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\gamma_k \ne 0\)</span>, in additive model.</p></li>
</ul></li>
</ul>
<p>In order to test these effects (interaction in the interaction model and
main effects in the additive model), <span class="math inline">\(F\)</span>-tests are developed using Sums of
Squares, Mean Squares, and degrees of freedom similar to those in
Chapter <a href="chapter3.html#chapter3">3</a>.

We
won’t worry about the details of the sums of squares formulas but you should
remember the sums of squares decomposition, which still applies<a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a>. 

Table <a href="chapter4.html#tab:Table4-1">4.1</a>
summarizes the ANOVA results you will obtain for the interaction
model and Table <a href="chapter4.html#tab:Table4-2">4.2</a> provides the similar general results for the additive
model. As we saw in Chapter <a href="chapter3.html#chapter3">3</a>, the degrees of freedom are the amount of
information that is free to vary at a particular level and that rule generally holds
here. For example, for factor A with <span class="math inline">\(J\)</span> levels, there are <span class="math inline">\(J-1\)</span> parameters that
are free since the baseline is fixed. The residual degrees of freedom for both
models are not as easily explained but have a simple formula. Note that the sum
of the degrees of freedom from the main effects, (interaction if present), and
error need to equal <span class="math inline">\(N-1\)</span>, just like in the One-Way ANOVA table.</p>

<table>
<caption><span id="tab:Table4-1">Table 4.1: </span> Interaction Model ANOVA Table.</caption>
<colgroup>
<col width="18%" />
<col width="19%" />
<col width="22%" />
<col width="24%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Source</strong>    </th>
<th align="left"><strong>DF</strong>     </th>
<th align="left"><strong>SS</strong></th>
<th align="left"><strong>MS</strong></th>
<th align="left"><strong>F-statistics</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left"><span class="math inline">\(J-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A=\text{SS}_A/\text{df}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left"><span class="math inline">\(K-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B=\text{SS}_B/\text{df}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B/\text{MS}_E\)</span></td>
</tr>
<tr class="odd">
<td align="left">A:B (interaction)</td>
<td align="left"><span class="math inline">\((J-1)(K-1)\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_{AB}\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_{AB}=\text{SS}_{AB}/\text{df}_{AB}\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_{AB}/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(N-JK\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_E\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_E=\text{SS}_E/\text{df}_E\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><b><font
color='red'>Total</font></b></td>
<td align="left"><span class="math inline">\(\color{red}{\mathbf{N-1}}\)</span></td>
<td align="left"><span class="math inline">\(\color{red}{\textbf{SS}_{\textbf{Total}}}\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>

<table>
<caption><span id="tab:Table4-2">Table 4.2: </span> Additive Model ANOVA Table.</caption>
<colgroup>
<col width="19%" />
<col width="20%" />
<col width="24%" />
<col width="21%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Source</strong>    </th>
<th align="left"><strong>DF</strong>     </th>
<th align="left"><strong>SS</strong></th>
<th align="left"><strong>MS</strong></th>
<th align="left"><strong>F-statistics</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left"><span class="math inline">\(J-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A=\text{SS}_A/\text{df}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left"><span class="math inline">\(K-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B=\text{SS}_B/\text{df}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B/\text{MS}_E\)</span></td>
</tr>
<tr class="odd">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(N-J-K+1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_E\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_E=\text{SS}_E/\text{df}_E\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><b><font
color='red'>Total</font></b></td>
<td align="left"><span class="math inline">\(\color{red}{\mathbf{N-1}}\)</span></td>
<td align="left"><span class="math inline">\(\color{red}{\textbf{SS}_{\textbf{Total}}}\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>The mean squares are formed by taking the sums of squares (we’ll let R find those
for us) and dividing by the <span class="math inline">\(df\)</span> in the row.

The <span class="math inline">\(F\)</span>-ratios are found by taking
the mean squares from the row and dividing by the mean squared error (<span class="math inline">\(\text{MS}_E\)</span>).
They follow <span class="math inline">\(F\)</span>-distributions with numerator degrees
of freedom from the row and denominator degrees of freedom from the Error row
(in R output this the <code>Residuals</code> row).


It is possible to develop permutation
tests for these methods but some
technical issues arise in doing permutation tests for interaction model components
so we will not use them here. This means we will have to place even more
emphasis on meeting the assumptions since we only have the parametric method
available.

</p>
<p>With some basic expectations about the ANOVA tables and <span class="math inline">\(F\)</span>-statistic construction
in mind, we can get to actually estimating the models and exploring the results.

The first example involves the fake paper towel data
displayed in Figure <a href="chapter4.html#fig:Figure4-1">4.1</a> and <a href="chapter4.html#fig:Figure4-2">4.2</a>. It appeared
that Scenario 5 was the correct
story since the lines were not parallel, but we need to know whether there is
evidence to suggest that the interaction is “real” and we get that through the
interaction hypothesis test. To fit the interaction model using <code>lm</code>,
the general formulation is <code>lm(y~x1*x2, data=...)</code>. The
order of the variables doesn’t matter and the most important part of the model,
to start with, relates to the interaction of the variables.
</p>
<p>The ANOVA table output
shows the results for the interaction model obtained by running the <code>anova</code>
function on the model called <code>m1</code>.

Specifically, the test that
<span class="math inline">\(H_0: \text{ All } \omega_{jk}\text{&#39;s} = 0\)</span> has a
test statistic of <span class="math inline">\(F(2,24)=1.92\)</span> (in the output from the row with
brands:drops) and a p-value of 0.17. So there is weak evidence against the null hypothesis of no interaction, with a 17% chance we would
observe a difference in the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> like we did or more
extreme if the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> really were all 0. So it seems that the interaction probably is not needed. Note that for the interaction
model components, R presents them with a colon, <code>:</code>, between the variable
names.
</p>
<pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(responses<span class="op">~</span>brand<span class="op">*</span>drops, <span class="dt">data=</span>pt)
<span class="kw">anova</span>(m1)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: responses
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)
## brand        1 4.3322  4.3322 10.5192 0.003458
## drops        2 4.8581  2.4290  5.8981 0.008251
## brand:drops  2 1.5801  0.7901  1.9184 0.168695
## Residuals   24 9.8840  0.4118</code></pre>
<p>It is useful to display the estimates from this model and we can utilize
<code>plot(allEffects(MODELNAME))</code> to visualize the results for the terms
in our models. If we turn on the options for <code>grid=T</code>, <code>multiline=T</code>,
and <code>ci.style="bars"</code> we will get a more useful version of the basic
“effect plot” for Two-Way ANOVA
models with interaction. The results of the estimated interaction model are
displayed in Figure <a href="chapter4.html#fig:Figure4-7">4.7</a>, which looks very similar to our
previous interaction plot. The only difference is that this comes from model
that assumes equal variance and these plots show 95% confidence intervals
for the means instead of the 1 standard error used above that was calculated using the variance of the observations at each combination of levels.
</p>

<div class="figure"><span id="fig:Figure4-7"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-7-1.png" alt="Plot of estimated results of interaction model for the paper towel performance data." width="576" />
<p class="caption">
Figure 4.7: Plot of estimated results of interaction model for the paper towel performance data.
</p>
</div>
<p>In the absence of evidence to include the
interaction, the model should be simplified to the additive model and the interpretation
focused on each main effect, conditional on having the other variable in the
model. To fit an additive model and not include an interaction, the model
formula involves a “+” instead of a “<code>*</code>” between the explanatory variables.</p>
<pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(responses<span class="op">~</span>brand<span class="op">+</span>drops, <span class="dt">data=</span>pt)</code></pre>
<p></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(m2)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: responses
##           Df  Sum Sq Mean Sq F value   Pr(&gt;F)
## brand      1  4.3322  4.3322  9.8251 0.004236
## drops      2  4.8581  2.4290  5.5089 0.010123
## Residuals 26 11.4641  0.4409</code></pre>
<p>The p-values for the main effects of <code>brand</code> and <code>drops</code> change slightly from the
results in the interaction model due to changes in the <span class="math inline">\(\text{MS}_E\)</span> from
0.4118 to 0.4409 (more variability is left over in the simpler model) and the
<span class="math inline">\(\text{DF}_{\text{error}}\)</span> that increases from 24 to 26. In both models, the
<span class="math inline">\(\text{SS}_{\text{Total}}\)</span> is the same (20.6544). In the interaction model,</p>
<p><span class="math display">\[\begin{array}{rl}
\text{SS}_{\text{Total}} &amp; = \text{SS}_{\text{brand}} + \text{SS}_{\text{drops}}
+ \text{SS}_{\text{brand:drops}} + \text{SS}_{\text{E}}\\
&amp; = 4.3322 + 4.8581 + 1.5801 + 9.8840\\
&amp; = 20.6544.\\
\end{array}\]</span></p>
<p>In the additive model, the variability that was attributed to the interaction term
in the interaction model (<span class="math inline">\(\text{SS}_{\text{brand:drops}} = 1.5801\)</span>) is pushed into the
<span class="math inline">\(\text{SS}_{\text{E}}\)</span>, which increases from 9.884 to 11.4641. The sums of squares
decomposition in the additive model is</p>
<p><span class="math display">\[\begin{array}{rl}
\text{SS}_{\text{Total}} &amp; = \text{SS}_{\text{brand}} + \text{SS}_{\text{drops}}
 + \text{SS}_{\text{E}} \\
&amp; = 4.3322 + 4.8581 + 11.4641 \\
&amp; = 20.6544. \\
\end{array}\]</span></p>
<p>This shows that the sums of squares decomposition applies in these more complicated
models as it did in the One-Way ANOVA.

It also shows that if the interaction is
removed from the model, that variability is lumped in with the other
unexplained variability that goes in the <span class="math inline">\(\text{SS}_{\text{E}}\)</span> in any model.</p>
<p>The fact that the sums of squares decomposition can be applied here is
useful, except that there is a small issue
with the main effect tests in the ANOVA table results that follow this
decomposition when the design is not balanced. It ends up that the tests in a
typical ANOVA table are only conditional on the tests higher up in the table. For
example, in the additive model ANOVA table, the <code>Brand</code> test is not
conditional on the <code>Drops</code> effect, but the <code>Drops</code> effect is conditional on the
<code>Brand</code> effect. To fix this issue, we have to use another type of sums of
squares, called <strong><em>Type II sums of squares</em></strong>.

They will no longer always
follow the rules of the sums of squares decomposition but they
will test the desired hypotheses. Specifically, they provide each test
conditional on any other terms at the same level of the model and match the
hypotheses written out earlier in this section. To get the “correct” ANOVA
results, the <code>car</code> (<span class="citation">Fox, Weisberg, and Price (<a href="#ref-R-car" role="doc-biblioref">2018</a><a href="#ref-R-car" role="doc-biblioref">a</a>)</span>, <span class="citation">Fox and Weisberg (<a href="#ref-Fox2011" role="doc-biblioref">2011</a>)</span>) package is required. We use the
<code>Anova</code> function on our linear models from here forward to get the “right”
tests in our ANOVA tables<a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a>.

Note how the case-sensitive nature of R code shows
up in the use of the capital-A <code>Anova</code> function instead of the <code>anova</code>
function used previously. In this case, because the design was balanced, the
results are the same using either function. Observational studies rarely
generate balanced designs (some designed studies can result in unbalanced
designs) so we will generally just use the Type II version of the sums of
squares. The <code>Anova</code> results using the Type II sums of
squares are slightly more conservative than the results from <code>anova</code>,
which are called Type I sums of squares.

The sums of squares decomposition no
longer can be applied, but it is a small sacrifice to get each test after
adjusting for all other variables<a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a>.
</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(car)
<span class="kw">Anova</span>(m2)</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: responses
##            Sum Sq Df F value   Pr(&gt;F)
## brand      4.3322  1  9.8251 0.004236
## drops      4.8581  2  5.5089 0.010123
## Residuals 11.4641 26</code></pre>
<p>The new output switches the columns around and doesn’t show you the mean squares,
but gives the most critical parts of the output. Here, there is no change in
results because it is balanced design with equal counts of responses in each
combination of the two explanatory variables.</p>
<p>The additive model, when appropriate, provides simpler interpretations for
each explanatory variable compared to models
with interactions because the effect of one variable is the same regardless of
the levels of the other variable and vice versa.

There are two tools to aid in
understanding the impacts of the two variables in the additive model. First,
the model summary provides estimated coefficients with interpretations like
those seen in Chapter <a href="chapter3.html#chapter3">3</a> (deviation of group <span class="math inline">\(j\)</span> or <span class="math inline">\(k\)</span> from
the baseline group’s mean), except with the additional wording of
“controlling for” the other variable
added to any of the discussion. Second, the term-plots now show each main
effect and how the groups differ with one panel for each of the two explanatory
variables in the model. These term-plots are created by holding the other
variable constant at one of its levels.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(m2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = responses ~ brand + drops, data = pt)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.4561 -0.4587  0.1297  0.4434  0.9695 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   1.8454     0.2425   7.611 4.45e-08
## brandB2       0.7600     0.2425   3.134  0.00424
## drops20      -0.4680     0.2970  -1.576  0.12715
## drops30      -0.9853     0.2970  -3.318  0.00269
## 
## Residual standard error: 0.664 on 26 degrees of freedom
## Multiple R-squared:  0.445,  Adjusted R-squared:  0.3809 
## F-statistic: 6.948 on 3 and 26 DF,  p-value: 0.001381</code></pre>
<p>In the model summary, the baseline combination estimated in the <code>(Intercept)</code>
row is for <code>Brand</code> <em>B1</em> and <code>Drops</code> 10 and estimates the mean failure
time as 1.85 seconds for this combination. As
before, the group labels that do not show up are the baseline but there are two
variables’ baselines to identify. Now the “simple” aspects of the additive
model show up. The interpretation of the <code>Brands</code> <em>B2</em> coefficient is as
a deviation from the baseline but it applies regardless of the level of
<code>Drops</code>. Any difference between <em>B1</em> and <em>B2</em> involves a shift up of 0.76 seconds
in the estimated mean failure time. Similarly, going from 10 (baseline) to 20
drops results in a drop in the estimated failure mean of 0.47 seconds and going
from 10 to 30 drops results in a drop of almost 1 second in the average time to
failure, both estimated changes are the same regardless of the brand of paper
towel being considered. Sometimes, especially in observational studies, we use
the terminology “controlled for” to remind the reader that the other variable
was present in the model<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a> and also explained some of the variability in the
responses. The term-plots for
the additive model (Figure <a href="chapter4.html#fig:Figure4-8">4.8</a>) help us visualize the
impacts of changes brand and changing water levels, holding the other
variable constant. The differences in heights in each panel correspond
to the coefficients just discussed.</p>
<p>(ref:fig4-8) Term-plots of additive model for paper towel data. Left panel displays
results for two brands and right panel for number of drops of water, each after
controlling for the other.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(m2))</code></pre>
<div class="figure"><span id="fig:Figure4-8"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-8-1.png" alt="(ref:fig4-8)" width="480" />
<p class="caption">
Figure 4.8: (ref:fig4-8)
</p>
</div>
</div>
<div id="section4-4" class="section level2">
<h2><span class="header-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</h2>
<p>The effects of dosage and delivery method of ascorbic acid on Guinea Pig
odontoblast growth was analyzed as a One-Way ANOVA in Section <a href="chapter3.html#section3-5">3.5</a>
by assessing evidence of any difference in the
means of any combinations of dosage method (Vit C capsule vs Orange Juice) and
three dosage amounts (0.5, 1, and 2 mg/day). Now we will consider the dosage
and delivery methods as two separate variables and explore their potential
interaction. A beanplot and interaction plot are provided in
Figure <a href="chapter4.html#fig:Figure4-9">4.9</a>.</p>

<div class="figure"><span id="fig:Figure4-9"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-9-1.png" alt="Beanplot and interaction plot of the odontoblast growth data set." width="576" />
<p class="caption">
Figure 4.9: Beanplot and interaction plot of the odontoblast growth data set.
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(ToothGrowth)
<span class="kw">require</span>(tibble)
ToothGrowth &lt;-<span class="st"> </span><span class="kw">as.tibble</span>(ToothGrowth)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">beanplot</span>(len<span class="op">~</span>supp<span class="op">*</span>dose, <span class="dt">data=</span>ToothGrowth, <span class="dt">side=</span><span class="st">&quot;b&quot;</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">40</span>),
         <span class="dt">main=</span><span class="st">&quot;Beanplot&quot;</span>, <span class="dt">col=</span><span class="kw">list</span>(<span class="st">&quot;white&quot;</span>,<span class="st">&quot;orange&quot;</span>), <span class="dt">xlab=</span><span class="st">&quot;Dosage&quot;</span>,
         <span class="dt">ylab=</span><span class="st">&quot;Tooth Growth&quot;</span>)
<span class="kw">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;VC&quot;</span>,<span class="st">&quot;OJ&quot;</span>), <span class="dt">fill=</span><span class="kw">c</span>(<span class="st">&quot;white&quot;</span>,<span class="st">&quot;orange&quot;</span>))
<span class="kw">intplot</span>(len<span class="op">~</span>supp<span class="op">*</span>dose, <span class="dt">data=</span>ToothGrowth, <span class="dt">col=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), 
        <span class="dt">main=</span><span class="st">&quot;Interaction Plot&quot;</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">40</span>))</code></pre>
<p>It appears that the effect of method changes based on the dosage as the
interaction plot seems to show some evidence of non-parallel lines.

Actually,
it appears that the effect of delivery method is parallel for doses 0.5 and 1.0
mg/day but that the effect of delivery method changes for 2 mg/day.</p>
<p>We can use the ANOVA <span class="math inline">\(F\)</span>-test for an interaction to assess whether the
interaction is “real” relative to the variability in the responses.

That is, is it larger than we would expect due to natural variation in the
data? If yes, then it is a real effect and we should account for it. The
following results fit the interaction model and provide an ANOVA table.</p>
<pre class="sourceCode r"><code class="sourceCode r">TG1 &lt;-<span class="st"> </span><span class="kw">lm</span>(len<span class="op">~</span>supp<span class="op">*</span>dose, <span class="dt">data=</span>ToothGrowth)
<span class="kw">Anova</span>(TG1)</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: len
##            Sum Sq Df  F value    Pr(&gt;F)
## supp       205.35  1  12.3170 0.0008936
## dose      2224.30  1 133.4151 &lt; 2.2e-16
## supp:dose   88.92  1   5.3335 0.0246314
## Residuals  933.63 56</code></pre>
<p>The R output is reporting an interaction test result of <span class="math inline">\(F(1,56)=5.3\)</span> with
a p-value of 0.025. But this should raise a red flag since the numerator
degrees of freedom are not what we should expect of <span class="math inline">\((K-1)*(J-1) = (2-1)*(3-1)=2\)</span>.

This brings up an issue in R when working
with categorical variables. If the levels of a categorical variable are entered
numerically, R will treat them as quantitative variables and not split out the
different levels of the categorical variable. To make sure that R treats
categorical variables the correct way, we should use the <code>factor</code>
function on any variables that are categorical but are coded numerically in the
data set. The following code creates a new variable called <code>dosef</code>
using the <code>factor</code> function that will help us obtain correct results from the linear
model.

The re-run of the ANOVA table provides the correct analysis and the
expected <span class="math inline">\(df\)</span> for the two rows of output involving <code>dosef</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">ToothGrowth<span class="op">$</span>dosef &lt;-<span class="st"> </span><span class="kw">factor</span>(ToothGrowth<span class="op">$</span>dose)
TG2 &lt;-<span class="st"> </span><span class="kw">lm</span>(len<span class="op">~</span>supp<span class="op">*</span>dosef, <span class="dt">data=</span>ToothGrowth)
<span class="kw">Anova</span>(TG2)</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: len
##             Sum Sq Df F value    Pr(&gt;F)
## supp        205.35  1  15.572 0.0002312
## dosef      2426.43  2  92.000 &lt; 2.2e-16
## supp:dosef  108.32  2   4.107 0.0218603
## Residuals   712.11 54</code></pre>
<p>The ANOVA <span class="math inline">\(F\)</span>-test for an interaction between supplement type and dosage level is
<span class="math inline">\(F(2,54)= 4.107\)</span> with a p-value of 0.022. So there is strong evidence of an interaction and we probably should reject the null hypothesis of no interaction between <em>Dosage</em> and <em>Delivery method</em>,
supporting a changing effect on odontoblast growth of dosage based on the delivery
method in the Guinea Pigs that were assigned.</p>
<p>Any similarities between this correct
result and the previous WRONG result are coincidence. I once
attended a Master’s thesis defense where the results from a similar model were not as
expected (small p-values in places they didn’t expect and large p-values in
places where they thought differences existed). During the presentation, the student
showed some ANOVA tables and the four level categorical variable had 1 numerator
<span class="math inline">\(df\)</span> in the ANOVA table. The student
passed with <em>major</em> revisions but had to re-run <strong>all</strong> the results and re-write
<strong>all</strong> the conclusions…

So be careful to check the ANOVA results (<span class="math inline">\(df\)</span>
and for the right number of expected model coefficients) to make
sure they match your expectations. This is one reason why you will be learning
to fill in ANOVA tables based on information about the study so that you can be
prepared to detect when your code has let you down<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a>. It
is also a great reason to explore term-plots and coefficient interpretations as
that can also help diagnose errors in model construction.</p>
<p>Getting back to the previous results, we now have enough background information
to more formally write up a
focused interpretation of these results. The 6+ hypothesis testing steps in
this situation would be focused on first identifying that the best analysis
here is as a Two-Way ANOVA situation (these data were analyzed in
Chapter <a href="chapter3.html#chapter3">3</a> as
a One-Way ANOVA but this version is better because it can explore whether there
is an interaction between delivery method and dosage).

We will use a 5%
significance level and start with assessing the evidence for an interaction. If
the interaction had been dropped, we would have reported the test results for the
interaction, then re-fit the additive model and used it to explore the main effect
tests and estimates for <em>Dose</em> and <em>Delivery method</em>.</p>

<ol style="list-style-type: decimal">
<li><p><strong>Hypotheses:</strong></p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No interaction between <em>Delivery method</em> and <em>Dose</em> on odontoblast
growth in population of guinea pigs</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\omega_{jk}\text{&#39;s}=0\)</span>.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Interaction between <em>Delivery method</em> and <em>Dose</em> on odontoblast
growth in population of guinea pigs</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\omega_{jk}\ne 0\)</span>.</p></li>
</ul></li>
<li><p><strong>Validity conditions:</strong>
</p>
<ul>
<li><p>Independence: </p>
<ul>
<li>This assumption is presumed to be met because we don’t know of a
reason why the independence of the measurements of odontoblast growth of
the guinea pigs as studied might be violated.</li>
</ul></li>
<li><p>Constant variance:</p>
<ul>
<li><p>To assess this assumption, we can use the diagnostic plots in
Figure <a href="chapter4.html#fig:Figure4-10">4.10</a>.</p></li>
<li><p>In the Residuals vs Fitted and the Scale-Location plots, the
differences in variability among the groups (see the different
x-axis positions for each group’s fitted values) is minor, so
there is not strong evidence of a problem with the equal variance
assumption.
 </p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(TG2, <span class="dt">pch=</span><span class="dv">16</span>) </code></pre>
<div class="figure"><span id="fig:Figure4-10"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-10-1.png" alt="Diagnostic plots for the interaction model for odontoblast         growth interaction model." width="960" />
<p class="caption">
Figure 4.10: Diagnostic plots for the interaction model for odontoblast growth interaction model.
</p>
</div></li>
<li><p>Normality of residuals:</p>
<ul>
<li>The QQ-Plot in Figure <a href="chapter4.html#fig:Figure4-10">4.10</a> does not suggest a
problem with this assumption. </li>
</ul></li>
</ul></li>
<li><p><strong>Calculate the test statistic for the interaction test.</strong></p>
<p></p>
<pre class="sourceCode r"><code class="sourceCode r">TG2 &lt;-<span class="st"> </span><span class="kw">lm</span>(len<span class="op">~</span>supp<span class="op">*</span>dosef, <span class="dt">data=</span>ToothGrowth)
<span class="kw">Anova</span>(TG2) </code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: len
##             Sum Sq Df F value    Pr(&gt;F)
## supp        205.35  1  15.572 0.0002312
## dosef      2426.43  2  92.000 &lt; 2.2e-16
## supp:dosef  108.32  2   4.107 0.0218603
## Residuals   712.11 54</code></pre>
<ul>
<li>The test statistic is <span class="math inline">\(F(2,54)=4.107\)</span>.</li>
</ul></li>
<li><p><strong>Find the p-value:</strong> </p>
<ul>
<li><p>The ANOVA <span class="math inline">\(F\)</span>-test p-value of 0.0219 for the interaction.</p></li>
<li><p>To find this p-value directly in R from the test statistic value and distribution, we can use the <code>pf</code> function.
</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="fl">4.107</span>, <span class="dt">df1=</span><span class="dv">2</span>, <span class="dt">df2=</span><span class="dv">54</span>, <span class="dt">lower.tail=</span>F)</code></pre>
<pre><code>## [1] 0.0218601</code></pre></li>
<li><p><strong>Make a decision:</strong></p>
<ul>
<li>Reject <span class="math inline">\(H_0\)</span> since the p-value (0.0219) is relatively small (less than 0.05). With a p-value
of 0.0219, there is about a 2.19% chance we would observe interaction like
we did (or more extreme) if none were truly present. This provides strong
evidence against the null hypothesis of no interaction between delivery
method and dosage on odontoblast growth so we would retain the interaction in the model.</li>
</ul></li>
<li><p><strong>Write a conclusion:</strong></p>
<ul>
<li>Therefore, the effects of dosage level (0.5, 1, or 2 mg/day) on
population average tooth odontoblast growth rates of Guinea pigs are changed
by the delivery (OJ, Vitamin C) method (and vice versa) and we should keep
the interaction in the model. With the random assignment of levels but not
random selection of subjects here, we could also write this as: Different
dosage levels cause different changes in the odontoblast growth based on the
delivery method for these guinea pigs.</li>
</ul></li>
</ol>
<p>In a Two-Way ANOVA, we need to go a little further to get to the final
interpretations since the models are more complicated. When there is an
interaction present, we should focus on the interaction plot or term-plot of
the interaction model for an interpretation of the form and pattern of the
interaction.

If the interaction were unimportant, then the hypotheses and
results should focus on the additive model results, especially the estimated
model coefficients. To see why we don’t spend much time with the estimated
model coefficients in an interaction model, the coefficients for this model is
provided:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(TG2)<span class="op">$</span>coefficients</code></pre>
<pre><code>##               Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)      13.23   1.148353 11.5208468 3.602548e-16
## suppVC           -5.25   1.624017 -3.2327258 2.092470e-03
## dosef1            9.47   1.624017  5.8312215 3.175641e-07
## dosef2           12.83   1.624017  7.9001660 1.429712e-10
## suppVC:dosef1    -0.68   2.296706 -0.2960762 7.683076e-01
## suppVC:dosef2     5.33   2.296706  2.3207148 2.410826e-02</code></pre>
<p>There are two <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> in the results, related to modifying the
estimates for doses of 1 (-0.68) and 2
(5.33) for the Vitamin C group. If you want to re-construct the fitted values
from the model that are displayed in Figure <a href="chapter4.html#fig:Figure4-11">4.11</a>, you have
to look for any
coefficients that are “turned on” for a combination of levels of interest. For
example, for the OJ group (solid line in Figure <a href="chapter4.html#fig:Figure4-11">4.11</a>), the
dosage of 0.5 mg/day
has an estimate of an average growth of approximately 13 mm. This is the
baseline group, so the model estimate for an observation in the OJ and 0.5 mg/day
dosage is simply <span class="math inline">\(\hat{y}_{i,\text{OJ},0.5mg}=\hat{\alpha}=13.23\)</span> microns.
For the OJ and 2 mg dosage estimate that has a value over 25 microns in the
plot, the model incorporates the deviation for the 2 mg dosage:
<span class="math inline">\(\hat{y}_{i,\text{OJ},2mg}=\hat{\alpha} + \hat{\tau}_{2mg}=13.23 + 12.83 = 26.06\)</span>
microns. For the Vitamin C group, another coefficient becomes involved from its “main
effect”. For the VC and 0.5 mg dosage level, the estimate is approximately 8 microns.
The pertinent model components are
<span class="math inline">\(\hat{y}_{i,\text{VC},0.5mg}=\hat{\alpha} + \hat{\gamma}_{\text{VC}}=13.23 + (-5.25) = 7.98\)</span>
microns. Finally, when we consider non-baseline results for both groups, three
coefficients are required to reconstruct the results in the plot. For example,
the estimate for the VC, 1 mg dosage is
<span class="math inline">\(\hat{y}_{i,\text{VC},1mg}=\hat{\alpha} + \hat{\tau}_{1mg} + \hat{\gamma}_{\text{VC}} + \hat{\omega}_{\text{VC},1mg} = 13.23 + 9.47 + (-5.25) +(-0.68)= 16.77\)</span> microns. We usually will by-pass all this
fun(!) with the coefficients in an interaction model and go from the ANOVA
interaction test to focusing on the pattern of the responses in the interaction
plot, but it is good to know that there are still model coefficients driving
our results.</p>

<div class="figure"><span id="fig:Figure4-11"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-11-1.png" alt="Term-plot for the estimated interaction for the Odontoblast Growth data." width="480" />
<p class="caption">
Figure 4.11: Term-plot for the estimated interaction for the Odontoblast Growth data.
</p>
</div>

<div class="figure"><span id="fig:Figure4-12"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-12-1.png" alt="Interaction plot for Odontoblast data with added CLD from Tukey’s HSD." width="960" />
<p class="caption">
Figure 4.12: Interaction plot for Odontoblast data with added CLD from Tukey’s HSD.
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(TG2), <span class="dt">grid=</span>T, <span class="dt">multiline=</span>T, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">ci.style=</span><span class="st">&quot;bars&quot;</span>)</code></pre>
<p>Given the presence of an important
interaction, then the final step in the interpretation here is to interpret the
results in the interaction plot or term-plot of the interaction model,
supported by the p-value suggesting evidence of a different effect of
supplement type based on the dosage level. To supplement this even more,
knowing which combinations of levels differ can enhance our discussion. Tukey’s
HSD results (specifically the CLD) can be added to the original interaction
plot by turning on the <code>cld=T</code> option in the <code>intplot</code> function as seen in
Figure <a href="chapter4.html#fig:Figure4-12">4.12</a>. Sometimes it is hard to see the letters and so
there is also a <code>cldshift=...</code> option to move the letters up or down, here a
value of 1 seemed to work.  

</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">intplot</span>(len<span class="op">~</span>supp<span class="op">*</span>dose, <span class="dt">data=</span>ToothGrowth, <span class="dt">col=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">cldshift=</span><span class="dv">1</span>,
        <span class="dt">cld=</span>T, <span class="dt">main=</span><span class="st">&quot;Interaction Plot with CLD&quot;</span>)</code></pre>
<p>The interpretation of the previous hypothesis test result can be concluded
with the following discussion. Generally increasing the dosage increases the mean growth except for
the 2 mg/day dosage level where the increase levels off in the OJ group (OJ 1
and 2 mg/day are not detectably different) and the differences between the two
delivery methods disappear at the highest dosage level. But for 0.5 and 1 mg/day
dosages, OJ is clearly better than VC by about 10 microns of growth on average.</p>
</div>
<div id="section4-5" class="section level2">
<h2><span class="header-section-number">4.5</span> Observational study example: The Psychology of Debt</h2>
<p>In this section, the analysis of a survey of <span class="math inline">\(N=464\)</span> randomly sampled
adults will be analyzed from a survey conducted by <span class="citation">Lea, Webley, and Walker (<a href="#ref-Lea1995" role="doc-biblioref">1995</a>)</span>
and available in the <code>debt</code> data set from the <code>faraway</code> package
<span class="citation">(Faraway <a href="#ref-R-faraway" role="doc-biblioref">2016</a>)</span>.

The subjects responded to a variety of questions
including whether they buy cigarettes (<code>cigbuy</code>: 0 if
no, 1 if yes), their housing situation (<code>house</code>: 1 = rent, 2 = mortgage,
and 3 = owned outright), their income group (<code>incomegp</code>: 1 =
lowest, 5 = highest), and their score on a continuous scale of attitudes about
debt (<code>prodebt</code>: 1 = least favorable, 5 = most favorable). The variable <code>prodebt</code>
was derived as the average of a series of questions about debt with each
question measured on an <strong><em>ordinal</em></strong> 1 to 5 scale, with higher values
corresponding to more positive responses about <span class="math inline">\(\underline{\text{going into debt}}\)</span>
of various kinds. The ordered scale on surveys that try to elicit your opinions on
topics with scales from 1 to 5 or 1 to 7 or even, sometimes, 1 to 10 is called
a <strong><em>Likert scale</em></strong> <span class="citation">(Likert <a href="#ref-Likert1932" role="doc-biblioref">1932</a>)</span>.  It is not a quantitative scale and really
should be handled more carefully than taking an average of a set responses. That
said, it is extremely common practice in social science research to treat ordinal
responses as if they are quantitative and take the average of many of them to
create a more continuous response variable like the one we are using here. If
you continue your statistics explorations, you will see some better techniques
for analyzing responses obtained in this fashion. That said, the scale of the
response is relatively easy to understand as an amount of willingness to go
into debt on a scale from 1 to 5 with higher values corresponding to more
willingness to be in debt.</p>
<p>This data set is typical of survey data where respondents were not required
to answer all questions and there are some
missing responses. We will clean out any individuals that failed to respond to
all questions using the <code>na.omit</code> function, which will return only subjects
that responded to every question in
the data set. But is this dangerous? Suppose that people did not want to
provide their income levels if they were in the lowest or, maybe, highest
income groups. Then we would be missing responses systematically and conclusions
could be biased because of ignoring these types of subjects. This is another
topic for more advanced statistical methods to try to handle but something
every researcher should worry about when selected subjects do not respond at
all or fail to answer some questions. This ties back into our discussion of who was sampled. We need to
think carefully about who was part of the sample but refused to participate and
how that might impact our inferences.</p>
<p>Ignoring this potential for bias in the
results for the moment, we are first interested in whether buying
cigarettes/not and income groups interact in their explanation of the
respondent’s mean opinions on being in debt. The interaction plot
(Figure <a href="chapter4.html#fig:Figure4-13">4.13</a>) may suggest an interaction between <code>cigbuy</code>
and <code>incomegp</code> from income levels 1 to 3 where the lines cross but it is
not as clear as the previous examples. The interaction <span class="math inline">\(F\)</span>-test helps us
objectively assess evidence for that interaction. Based on the plot, there do
not appear to be differences based on cigarette purchasing but there might be some
differences between the income groups. If there is no interaction present, then
this suggests that we might be in Scenario 2 or 3 where a single main effect of
interest is present.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(faraway)
<span class="kw">data</span>(debt)
<span class="kw">require</span>(tibble)
debt &lt;-<span class="st"> </span><span class="kw">as.tibble</span>(debt)
debt<span class="op">$</span>incomegp &lt;-<span class="st"> </span><span class="kw">factor</span>(debt<span class="op">$</span>incomegp)
debt<span class="op">$</span>cigbuy &lt;-<span class="st"> </span><span class="kw">factor</span>(debt<span class="op">$</span>cigbuy)
debtc &lt;-<span class="st"> </span><span class="kw">na.omit</span>(debt)</code></pre>
<p>(ref:fig4-13) Interaction plot array of <code>prodebt</code> by income group and buy cigarettes
(0=no, 1=yes).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">intplotarray</span>(prodebt<span class="op">~</span>cigbuy<span class="op">*</span>incomegp, <span class="dt">data=</span>debtc, <span class="dt">col=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>), <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre>
<div class="figure"><span id="fig:Figure4-13"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-13-1.png" alt="(ref:fig4-13)" width="960" />
<p class="caption">
Figure 4.13: (ref:fig4-13)
</p>
</div>
<p>As in other situations, and especially
with observational studies where a single large sample is analyzed, it is
important to check for balance - whether all the combinations of the two
predictor variables are similarly represented.

Even more critically, we need to
check whether all the combinations of levels of factors are measured. If a
combination is not measured, then we lose the ability to estimate the mean for
that combination and the ability to test for an interaction. A solution to that
problem would be to collapse the categories of one of the variables, changing
the definitions of the levels but if you fail to obtain information for all
combinations, you can’t work with the interaction model. In this situation, we
barely have enough information to proceed (the smallest <span class="math inline">\(n_{jk}\)</span> is 8 for
income group 4 that buys cigarettes). We have a very unbalanced design
with counts between 8 and 51 in the different combinations.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tally</span>(cigbuy<span class="op">~</span>incomegp, <span class="dt">data=</span>debtc)</code></pre>
<pre><code>##       incomegp
## cigbuy  1  2  3  4  5
##      0 24 40 45 47 51
##      1 23 29 18  8 19</code></pre>
<p>The test for the interaction is always
how we start our modeling in Two-Way ANOVA situations. The ANOVA table suggests
that there is little evidence of interaction between the income level and
buying cigarettes on the opinions of the respondents towards debt
(<span class="math inline">\(F(4,294)=1.0003\)</span>, p-value=0.408). This suggests that the initial assessment
that the interaction wasn’t too prominent
was correct. We should move to the additive model here but first need to check
the assumptions to make sure we can trust this initial test.
</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(car)
debt1 &lt;-<span class="st"> </span><span class="kw">lm</span>(prodebt<span class="op">~</span>incomegp<span class="op">*</span>cigbuy, <span class="dt">data=</span>debtc)
<span class="kw">Anova</span>(debt1)</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: prodebt
##                  Sum Sq  Df F value   Pr(&gt;F)
## incomegp          9.018   4  4.5766 0.001339
## cigbuy            0.703   1  1.4270 0.233222
## incomegp:cigbuy   1.971   4  1.0003 0.407656
## Residuals       144.835 294</code></pre>
<p>The diagnostic plots (Figure <a href="chapter4.html#fig:Figure4-14">4.14</a>) seem to be pretty
well-behaved with no apparent
violations of the normality assumption and no clear evidence of a violation of
the constant variance assumption. The observations would seem to be independent
because there is no indication of structure to the measurements of the survey
respondents that might create dependencies. In observational studies, violations
of the independence assumption might come from repeated measures of the same
person or multiple measurements within the same family/household or samples
that are clustered geographically.

The random sampling from a population should
allow inferences to a larger population except for that issue of removing
partially missing responses.

We also don’t have much information on the
population sampled, so will just leave this vague here but know that there is a
population these conclusions apply to since it was random sample. All of this
suggests proceeding to fitting and exploring the additive model is reasonable
here. No causal inferences are possible because this is an observational study.</p>
<p>(ref:fig4-14) Diagnostic plot for <code>prodebt</code> by income group and buy
cigarettes/not interaction model.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(debt1)</code></pre>
<div class="figure"><span id="fig:Figure4-14"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-14-1.png" alt="(ref:fig4-14)" width="960" />
<p class="caption">
Figure 4.14: (ref:fig4-14)
</p>
</div>

<ol style="list-style-type: decimal">
<li><p><strong>Hypotheses (Two sets apply when the additive model is the focus!):</strong></p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No difference in means for <code>prodebt</code> for income groups in
population, given cigarette buying in model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\tau_j\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means for <code>prodebt</code> for income group in
population, given cigarette buying in model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> Not all <span class="math inline">\(\tau_j\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_0\)</span>: No difference in means for <code>prodebt</code> for cigarette
buying/not in population, given income group in model </span></p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\gamma_k\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means for <code>prodebt</code> for cigarette
buying/not in population, given income group in model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> Not all <span class="math inline">\(\gamma_k\text{&#39;s} = 0\)</span> in additive model.</p></li>
</ul></li>
<li><p><strong>Validity conditions – discussed above but with new plots for the additive model:</strong>
</p>
<pre class="sourceCode r"><code class="sourceCode r">debt1r &lt;-<span class="st"> </span><span class="kw">lm</span>(prodebt<span class="op">~</span>incomegp<span class="op">+</span>cigbuy, <span class="dt">data=</span>debtc)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(debt1r)</code></pre>
<div class="figure"><span id="fig:Figure4-15"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-15-1.png" alt="Diagnostic plot for ``prodebt`` by income group and buy   cigarettes/not" width="960" />
<p class="caption">
Figure 4.15: Diagnostic plot for <code>prodebt</code> by income group and buy cigarettes/not
</p>
</div>
<ul>
<li><p>Constant Variance:</p>
<ul>
<li>In the Residuals vs Fitted and the Scale-Location plots in
Figure <a href="chapter4.html#fig:Figure4-15">4.15</a>, the differences in variability among
groups is minor and nothing suggests a violation. <strong>If you change
models, you should always revisit the diagnostic plots to make sure you
didn’t create problems that were not present in more complicated models.</strong>
 </li>
</ul></li>
<li><p>Normality of residuals:</p>
<ul>
<li>The QQ-Plot in Figure <a href="chapter4.html#fig:Figure4-15">4.15</a> does not suggest
a problem with this assumption. </li>
</ul></li>
</ul></li>
<li><p><strong>Calculate the test statistic for the two main effect tests.</strong></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Anova</span>(debt1r)</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: prodebt
##            Sum Sq  Df F value   Pr(&gt;F)
## incomegp    9.018   4  4.5766 0.001335
## cigbuy      0.703   1  1.4270 0.233210
## Residuals 146.806 298</code></pre>
<ul>
<li>The test statistics are <span class="math inline">\(F(4,298)=4.577\)</span> and <span class="math inline">\(F(1,298)=1.427\)</span>.</li>
</ul></li>
<li><p><strong>Find the p-value:</strong></p>
<ul>
<li>The ANOVA <span class="math inline">\(F\)</span>-test p-values are 0.001335 for the income group
variable (conditional on cigarette buy) and 0.2232 for
the cigarette buy variable (conditional on income group).</li>
</ul></li>
<li><p><strong>Make decisions:</strong></p>
<ul>
<li>Reject <span class="math inline">\(H_0\)</span> of no income group differences (p-value=0.0013) and fail to
reject <span class="math inline">\(H_0\)</span> of no cigarette buying differences (p-value=0.2232),
each after controlling for the other variable.</li>
</ul></li>
<li><p><strong>Write a conclusion:</strong></p>
<ul>
<li>There was initially little to no evidence to support retaining the interaction
of income group and cigarette buying on pro-debt feelings
(<span class="math inline">\(F(4,294)=1.00, \text{p-value} =0.408\)</span>) so the interaction was dropped
from the model. There is strong evidence of some difference in the mean
pro-debt feelings in the population across the income groups, after
adjusting for cigarette buying. There is little to no evidence of a
difference in the mean pro-debt feelings in the population based on
cigarette buying/not, after adjusting for income group.</li>
</ul></li>
</ol>
<p>So we learned that the additive model
was more appropriate for these responses and that the results resemble Scenario
2 or 3 with only one main effect being important. In the additive model, the
coefficients can be interpreted as shifts from the baseline after controlling
for the other variable in the model. Figure <a href="chapter4.html#fig:Figure4-16">4.16</a> shows the
increasing average
comfort with being in debt as the income groups go up. Being a cigarette buyer
was related to a lower comfort level with debt. But compare the y-axis scales
in the two plots – the differences in the means across income groups are almost
0.5 points on a 5 point scale whereas the difference across <code>cigbuy</code>’s
two levels is less than 0.15 units. The error bars for the 95% confidence
intervals are of similar width but the differences in means show up clearly in
the income group term-plot. This is all indirectly related to the size of the
p-values for each term in the additive model but hopefully helps to build some
intuition on the reason for differences.</p>
<p>(ref:fig4-16) Term-plots for the <code>prodebt</code> response additive model with left
panel for income group and the right panel for buying cigarettes or not
(1 for yes).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(debt1r))</code></pre>
<div class="figure"><span id="fig:Figure4-16"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-16-1.png" alt="(ref:fig4-16)" width="960" />
<p class="caption">
Figure 4.16: (ref:fig4-16)
</p>
</div>
<p>The estimated coefficients can also be
interesting to interpret for the additive model. Here are the model summary coefficients:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(debt1r)<span class="op">$</span>coefficients</code></pre>
<pre><code>##                Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)  3.05483517 0.11127284 27.4535561 1.357428e-83
## incomegp2    0.01640636 0.13288796  0.1234601 9.018260e-01
## incomegp3    0.17477182 0.13649309  1.2804444 2.013846e-01
## incomegp4    0.16900515 0.14274836  1.1839376 2.373813e-01
## incomegp5    0.46833117 0.13377661  3.5008449 5.347171e-04
## cigbuy1     -0.10640228 0.08907259 -1.1945569 2.332101e-01</code></pre>
<p>In the model, the baseline group is for non-cigarette buyers (<code>cigbuy=0</code>)
and income group 1 with <span class="math inline">\(\hat{\alpha}= 3.055\)</span> points. Regardless of the
<code>cigbuy</code> level, the difference between income groups 2 and 1 is estimated
to be <span class="math inline">\(\hat{\tau}_2=0.016\)</span>, an increase in the mean score of 0.016 points.
Similarly, the difference between income groups 3 and 1 is <span class="math inline">\(\hat{\tau}_3=0.175\)</span>
points, regardless of cigarette smoking status. The estimated difference
between cigarette buyers and non-buyers was estimated as
<span class="math inline">\(\hat{\gamma}_2=-0.106\)</span> points for any income group, remember that this
variable had a moderately
large p-value in this model. The additive model-based estimates for all
six combinations can be found in Table <a href="chapter4.html#tab:Table4-3">4.3</a>.</p>
<p>(ref:tab4-3) Calculations to construct the estimates for all combinations
of variables for the <code>prodebt</code> additive model.</p>

<table>
<caption><span id="tab:Table4-3">Table 4.3: </span> (ref:tab4-3)</caption>
<colgroup>
<col width="14%" />
<col width="13%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\color{red}{\text{Cig}}\)</span><br />
<span class="math inline">\(\color{red}{\text{Buy}}\)</span></th>
<th align="left"><span class="math inline">\(\color{blue}{\textbf{Income}}\)</span><br />
<span class="math inline">\(\color{blue}{\textbf{Group 1}}\)</span></th>
<th align="left"><span class="math inline">\(\color{blue}{\textbf{Income}}\)</span><br />
<span class="math inline">\(\color{blue}{\textbf{Group 2}}\)</span></th>
<th align="left"><span class="math inline">\(\color{blue}{\textbf{Income}}\)</span><br />
<span class="math inline">\(\color{blue}{\textbf{Group 3}}\)</span></th>
<th align="left"><span class="math inline">\(\color{blue}{\textbf{Income}}\)</span><br />
<span class="math inline">\(\color{blue}{\textbf{Group 4}}\)</span></th>
<th align="left"><span class="math inline">\(\color{blue}{\textbf{Income}}\)</span><br />
<span class="math inline">\(\color{blue}{\textbf{Group 5}}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\color{red}{\text{0:No}}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha} ={3.055}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha} + \hat{\tau}_2\)</span><br />
<span class="math inline">\(=3.055 + 0.016\)</span><br />
<span class="math inline">\(= 3.071\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha} + \hat{\tau}_3\)</span><br />
<span class="math inline">\(=3.055 + 0.175\)</span><br />
<span class="math inline">\(=3.230\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha} + \hat{\tau}_4\)</span><br />
<span class="math inline">\(=3.055 + 0.169\)</span><br />
<span class="math inline">\(=3.224\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha} + \hat{\tau}_5\)</span><br />
<span class="math inline">\(=3.055 + 0.468\)</span><br />
<span class="math inline">\(=3.523\)</span><br />
</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\color{red}{\text{1:}\text{Yes}}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\gamma}_2\)</span><br />
<span class="math inline">\(=3.055\)</span><br />
<span class="math inline">\(-0.106\)</span><br />
<span class="math inline">\(=2.949\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_2+\hat{\gamma}_2\)</span><br />
<span class="math inline">\(=3.055+0.016\)</span><br />
<span class="math inline">\(-0.106\)</span><br />
<span class="math inline">\(=2.965\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_3+\hat{\gamma}_2\)</span><br />
<span class="math inline">\(=3.055+0.175\)</span><br />
<span class="math inline">\(-0.106\)</span><br />
<span class="math inline">\(=3.124\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_4+\hat{\gamma}_2\)</span><br />
<span class="math inline">\(=3.055+0.169\)</span><br />
<span class="math inline">\(-0.106\)</span><br />
<span class="math inline">\(=3.118\)</span></td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_5+\hat{\gamma}_2\)</span><br />
<span class="math inline">\(=3.055+0.468\)</span><br />
<span class="math inline">\(-0.106\)</span><br />
<span class="math inline">\(=3.417\)</span></td>
</tr>
</tbody>
</table>

<p>One final plot of the fitted values
from this additive model in Figure <a href="chapter4.html#fig:Figure4-17">4.17</a> hopefully crystallizes
the implications
of an additive model and reinforces that this model creates and assumes that
the differences across levels of one variable are the same regardless of the
level of the other variable and that this creates parallel lines. The
difference between <code>cigbuy</code> levels across all income groups is a drop in
-0.106 points. The income groups
have the same differences regardless of cigarette buying or not, with income
group 5 much higher than the other four groups.</p>
<p>(ref:fig4-17) Illustration of the results from Table <a href="chapter4.html#tab:Table4-2">4.2</a>
showing the combined impacts
of the components of the additive model for <code>prodebt</code>. Panel (a) uses income
groups on the x-axis and different lines for cigarette buyers (1) or not (0).
Panel (b) displays the different income groups as lines with the cigarette
buying status on the x-axis.</p>
<div class="figure"><span id="fig:Figure4-17"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-17-1.png" alt="(ref:fig4-17)" width="576" />
<p class="caption">
Figure 4.17: (ref:fig4-17)
</p>
</div>

<p><strong>In general, we proceed through the following steps in any 2-WAY ANOVA situation:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Make an interaction plot.</p></li>
<li><p>Fit the interaction model; examine the test for the interaction.</p></li>
<li><p>Check the residual diagnostic plots for the interaction model (especially
normality and equal variance).</p>
<ul>
<li>If there is a problem with normality or
equal variance, consider a “transformation” of the response as discussed in
Chapter <a href="chapter7.html#chapter7">7</a>. This can help make the responses have similar
variances or responses (and the model residuals) to be more normal, but sometimes not both. </li>
</ul></li>
<li><p>If the interaction test has a small p-value, that is your main result. Focus on
the interaction plot from (1) to fully understand the results, adding Tukey’s
HSD  results to see which means of the combinations of levels are detected as
being different.</p></li>
<li><p>If the interaction is not considered important, then re-fit the model without
the interaction (additive model) and re-check the diagnostic plots. If the
diagnostics are reasonable to proceed:</p>
<ul>
<li><p>Focus on the results for each explanatory
variable, using Type II tests especially if the design is not balanced.</p></li>
<li><p>Report the initial interaction test
results and the results for the test for each variable from the model
that is re-fit without the interaction.</p></li>
<li><p>Model coefficients are interesting as they are shifts from baseline
for each level of each variable, controlling for the other variable –
interpret those differences if the number of levels is not
too great.</p></li>
</ul></li>
</ol>
<p>Whether you end up favoring an additive or interaction model, all steps of the
hypothesis testing protocol should be engaged and a story based on the final results should be compiled, supported by the graphical displays.</p>
</div>
<div id="section4-6" class="section level2">
<h2><span class="header-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs</h2>
<p>In some situations, it is too expensive
to replicate combinations of treatments and only one observation at each
combination of the two explanatory variables, A and B, is possible. In these
situations, even though we have information about all combinations of A and B,
it is no longer possible to test for an interaction. Our regular rules for
degrees of freedom show that we have nothing left for the error degrees of
freedom and so we have to drop the interaction and call that potential
interaction variability “error”.

</p>
<p>We can still perform an analysis of the
responses but an issue occurs with trying to estimate the interaction
<span class="math inline">\(F\)</span>-test statistic – we run out of degrees of freedom for the error. To
illustrate these methods, the paper towel example
is revisited except that only one response for each combination is used. Now
the entire data set can be displayed:</p>
<pre class="sourceCode r"><code class="sourceCode r">ptR &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/ptR.csv&quot;</span>)
ptR<span class="op">$</span>dropsf &lt;-<span class="st"> </span><span class="kw">factor</span>(ptR<span class="op">$</span>drops)
ptR<span class="op">$</span>brand &lt;-<span class="st"> </span><span class="kw">factor</span>(ptR<span class="op">$</span>brand)
ptR</code></pre>
<pre><code>## # A tibble: 6 x 4
##   brand drops responses dropsf
##   &lt;fct&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; 
## 1 B1       10     1.91  10    
## 2 B2       10     3.05  10    
## 3 B1       20     0.774 20    
## 4 B2       20     2.84  20    
## 5 B1       30     1.56  30    
## 6 B2       30     0.547 30</code></pre>
<p>Upon first inspection the interaction plot in Figure <a href="chapter4.html#fig:Figure4-18">4.18</a>
looks like there might be
some interesting interactions present. But remember now that there is only a
single observation at each combination of the brands and water levels so there
is not much power to detect differences in this sort of situation and no replicates
at any combinations of levels that allow estimation of SEs so no bands are produced in the
plot. 
</p>

<div class="figure"><span id="fig:Figure4-18"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-18-1.png" alt="Interaction plot in paper towel data set with no replication." width="480" />
<p class="caption">
Figure 4.18: Interaction plot in paper towel data set with no replication.
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">intplot</span>(responses<span class="op">~</span>brand<span class="op">*</span>dropsf, <span class="dt">data=</span>ptR, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre>
<p>The next step would be to assess the
statistical evidence related to an interaction between <code>Brand</code> and
<code>Drops</code>. A problem will arise in trying to form the ANOVA table as you
would see this when you run the <code>anova</code><a href="#fn61" class="footnote-ref" id="fnref61"><sup>61</sup></a> function on the interaction model:
</p>

<pre><code>&gt; anova(lm(responses~dropsf*brand,data=ptR))
Analysis of Variance Table
Response: responses
             Df  Sum Sq Mean Sq F value Pr(&gt;F)
dropsf        2 2.03872 1.01936               
brand         1 0.80663 0.80663               
dropsf:brand  2 2.48773 1.24386               
Residuals     0 0.00000                       
Warning message:
In anova.lm(lm(responses ~ dropsf * brand, data = ptR)) :
  ANOVA F-tests on an essentially perfect fit are unreliable</code></pre>

<p>Warning messages in R output show up after you run functions that contain
problems and are generally not a good thing, but can sometimes be ignored. In
this case, the warning message is not needed – there are no <span class="math inline">\(F\)</span>-statistics or
p-values in the results so we know there are some issues with the results. The
<strong>Residuals</strong> line is key here – Residuals with 0 <em>df</em> and sums of
squares of 0. Without replication, there are no degrees of freedom left to
estimate the residual error. My first statistics professor,
Gordon Bril at Luther College, used to refer to this as “shooting your load” by
fitting too many terms in the model given the number of observations available.
Maybe this is a bit graphic but hopefully will help you remember the need for
replication if you want to estimate interactions – it did for me. Without
replication of observations, we run out of information to estimate and test all
the desired model components.</p>
<p>So what can we do if we can’t afford replication but want to study two variables in the same study? We can <em>assume</em> that the
interaction does not exist and use those degrees of freedom and variability as
the error variability. When we drop the interaction from Two-Way
models, the interaction variability is added into the <span class="math inline">\(\text{SS}_E\)</span>
so this is interaction between the variables. We are not able to test for an
interaction so must rely on the interaction plot to assess whether an interaction
might be present. Figure <a href="chapter4.html#fig:Figure4-18">4.18</a> suggests there might be an
interaction in these data (the
two brands’ lines cross noticeably suggesting non-parallel lines).

So in this
case, assuming no interaction is present is hard to justify. But if we proceed
under this dangerous and untestable assumption, tests for the main effects can be developed.
</p>
<pre class="sourceCode r"><code class="sourceCode r">norep1 &lt;-<span class="st"> </span><span class="kw">lm</span>(responses<span class="op">~</span>dropsf<span class="op">+</span>brand, <span class="dt">data=</span>ptR)
<span class="kw">Anova</span>(norep1)</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: responses
##            Sum Sq Df F value Pr(&gt;F)
## dropsf    2.03872  2  0.8195 0.5496
## brand     0.80663  1  0.6485 0.5052
## Residuals 2.48773  2</code></pre>
<p>In the additive model, the last row of the ANOVA table that is called the
<code>Residuals</code> row is really the interaction row from the interaction model
ANOVA table. Neither main effect had a small p-value
(<em>Drops</em>: <span class="math inline">\(F(2,2)=0.82, \text{ p-value}=0.55\)</span> and
<em>Brand</em>: <span class="math inline">\(F(1,2)=0.65, \text{ p-value}=0.51\)</span>) in the additive model. To
get small p-values with the small sample sizes that unreplicated designs would generate, the differences would need to be
<strong>very</strong> large because the residual degrees of freedom have become very small.
 
The term-plots in Figure <a href="chapter4.html#fig:Figure4-19">4.19</a> show that the
differences among the levels are small relative to the residual variability as
seen in the error bars around each point estimate.</p>
<p>(ref:fig4-19) Term-plots for the additive model in paper towel data set with no
replication.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(norep1))</code></pre>
<div class="figure"><span id="fig:Figure4-19"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-19-1.png" alt="(ref:fig4-19)" width="480" />
<p class="caption">
Figure 4.19: (ref:fig4-19)
</p>
</div>
<p>Hopefully by pushing the limits there
are two conclusions available from this section. First, replication is
important, both in being able to perform tests for interactions and for having
enough power to detect differences for the main effects. Second, when dropping
from the interaction model to additive model, the variability explained by the
interaction term is pushed into the error term, whether replication is
available or not.</p>
</div>
<div id="section4-7" class="section level2">
<h2><span class="header-section-number">4.7</span> Chapter summary</h2>
<p>In this chapter, methods for handling two different categorical predictors
in the same model with a
continuous response were developed. The methods build on techniques from
Chapter <a href="chapter3.html#chapter3">3</a> for the One-Way ANOVA and there are connections
between the two
models. This was most clearly seen in the guinea pig data set that was analyzed
in both chapters. When two factors are available, it is better to start with
the methods developed in this chapter because the interaction between the
factors can, potentially, be separated from their main effects. The additive
model is easier to interpret but should only be used when no evidence of an
interaction is present. When an interaction is determined to be present, the
main effects should not be interpreted and the interaction plot in combination
with Tukey’s HSD provides information on the important aspects of the results.</p>
<ul>
<li><p>If the interaction is retained in the model, there are two things you want
to do with interpreting the interaction:</p>
<ol style="list-style-type: decimal">
<li><p>Describe the interaction, going through the changes from left to right
in the interaction plot or term-plot for each level of the other variable.</p></li>
<li><p>Suggest optimal and worst combinations of the two variables to describe the highest and lowest possible estimated mean responses.</p>
<ol style="list-style-type: lower-alpha">
<li>For example, you might want to identify a dosage and delivery
method for the guinea pigs to recommend and one to avoid if you
want to optimize odontoblast growth.</li>
</ol></li>
</ol></li>
<li><p>If there is no interaction, then the additive model provides information
on each of the variables and the differences across levels of each variable
are the same regardless of the levels of the other variable.</p>
<ul>
<li>You can describe the deviations from baseline as in Chapter <a href="chapter3.html#chapter3">3</a>,
but for each variable, noting that you are controlling for the variable.</li>
</ul></li>
</ul>
<p>Some statisticians might have different
recommendations for dealing with interactions and main effects, especially in
the context of evidence of an interaction. We have chosen to focus on tests for
interactions to screen for “real” interactions and then interpret the
interaction plots aided by the Tukey’s HSD for determining which combinations
of levels are detectably different. Some suggest exploring the main
effects tests even with interactions present. In some cases, those results are
interesting but in others the results can be misleading and we wanted to avoid
trying to parse out the scenarios when it might be safe to focus on the main effects in the presence of important interactions. Consider two scenarios, one where
the main effects have large p-values but the interaction has a small p-value
and the other where the main effects and the interaction all have small
p-values. The methods discussed in this chapter allow us to effectively arrive
at the interpretation of the differences in the results across the combinations
of the treatments due to the interaction having a small p-value. The main
effects results are secondary results at best when the interaction is important
because we know that impacts of one explanatory variable is changing based on
the levels of the other variable.</p>
<p>Chapter <a href="chapter5.html#chapter5">5</a> presents a bit of a different set of statistical
methods that allow analyses of data sets similar
to those considered in the last two chapters but with a categorical response
variable. The methods are very different in application but are quite similar in overall goals
to those in Chapter <a href="chapter3.html#chapter3">3</a> where differences in responses where explored
across groups. After Chapter <a href="chapter5.html#chapter5">5</a>, the rest of the semester will
return to fitting models using the <code>lm</code> function as used here, but
incorporating quantitative predictor variables and
then eventually incorporating both categorical and quantitative predictor
variables. The methods in Chapter <a href="chapter8.html#chapter8">8</a> are actually quite similar
to those considered here, so the better you understand these models, the easier that material will be master.</p>
</div>
<div id="section4-8" class="section level2">
<h2><span class="header-section-number">4.8</span> Summary of important R code</h2>
<p>The main components of R code used in this chapter follow with components to
modify in lighter and/or ALL CAPS text, remembering that any R
packages mentioned need to be installed and loaded for this code to have a
chance of working:</p>
<ul>
<li><p><strong>tally(<font color='red'>A</font>~<font color='red'>B</font>,
data=<font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li><p>Requires the <code>mosaic</code> package be loaded.</p></li>
<li><p>Provides the counts of observations in each combination of categorical
predictor variables A and B, used to check for balance and understand sample
sizes in each combination. </p></li>
</ul></li>
<li><p><strong><font color='red'>DATASETNAME</font>$<font color='red'>VARIABLENAME</font> <code>&lt;-</code>
factor(<font color='red'>DATASETNAME</font>$<font color='red'>VARIABLENAME</font>)</strong></p>
<ul>
<li>Use the <code>factor</code> function on any numerically coded
explanatory variable where the numerical codes represent levels of a
categorical variable. </li>
</ul></li>
<li><p><strong>intplot(<font color='red'>Y</font>~<font color='red'>A</font><code>*</code><font color='red'>B</font>,
data=<font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li><p>Download and install using:</p>
<p><code>source("http://www.math.montana.edu/courses/s217/documents/intplotfunctions.R")</code></p></li>
<li><p>Provides interaction plot. </p></li>
</ul></li>
<li><p><strong>intplotarray(<font color='red'>Y</font>~<font color='red'>A</font><code>*</code><font color='red'>B</font>,
data=<font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li><p>Download and install using:</p>
<p><code>source("http://www.math.montana.edu/courses/s217/documents/intplotfunctions.R")</code></p></li>
<li><p>Provides interaction plot array that makes interaction plots switching explanatory variable roles and makes beanplots of the main effects.
</p></li>
</ul></li>
<li><p><strong><font color='red'>INTERACTIONMODELNAME</font> <code>&lt;-</code>
lm(<font color='red'>Y</font>~<font color='red'>A</font><code>*</code><font color='red'>B</font>,
data=<font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li><p>Fits the interaction model with main effects for A and B and an
interaction between them.</p></li>
<li><p>This is the first model that should be fit in Two-Way ANOVA
modeling situations.</p></li>
</ul></li>
<li><p><strong><font color='red'>ADDITIVEMODELNAME</font> <code>&lt;-</code>
lm(<font color='red'>Y</font>~<font color='red'>A</font>+<font color='red'>B</font>,
data=<font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li><p>Fits the additive model with only main effects for A and B but no
interaction between them.</p></li>
<li><p>Should only be used if the interaction has been decided to be
unimportant using a test for the interaction.</p></li>
</ul></li>
<li><p><strong>summary(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li>Generates model summary information including the estimated model coefficients,
SEs, t-tests, and p-values.</li>
</ul></li>
<li><p><strong>Anova(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li><p>Requires the <code>car</code> package to be loaded.</p></li>
<li><p>Generates a Type II Sums of Squares ANOVA table that is useful for
both additive and interaction models, but it most important to use
when working with the additive model as it provides inferences for
each term conditional on the other one. </p></li>
</ul></li>
</ul>

<ul>
<li><p><strong>par(mfrow=c(2,2)); plot(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li>Generates four diagnostic plots including the Residuals vs Fitted and
Normal Q-Q plot.</li>
</ul></li>
<li><p><strong>plot(allEffects(<font color='red'>MODELNAME</font>))</strong></p>
<ul>
<li><p>Requires the <code>effects</code> package be loaded.</p></li>
<li><p>Plots the results from the estimated model.
</p></li>
</ul></li>
</ul>
</div>
<div id="section4-9" class="section level2">
<h2><span class="header-section-number">4.9</span> Practice problems</h2>
<p>To practice the Two-Way ANOVA, consider a data set on <span class="math inline">\(N=861\)</span> ACT
Mathematics Usage Test scores from 1987. The test was given to a
sample of high school seniors who met one of three profiles of high school
mathematics course
work: (a) Algebra I only; (b) two Algebra courses and Geometry; and (c) two
Algebra courses, Geometry, Trigonometry, Advanced Mathematics, and Beginning
Calculus. These data were generated from summary statistics for one particular
form of the test as reported by <span class="citation">Doolittle and Welch (<a href="#ref-Doolittle1989" role="doc-biblioref">1989</a>)</span>. The source of this version of
the data set is <span class="citation">Ramsey and Schafer (<a href="#ref-Ramsey2012" role="doc-biblioref">2012</a>)</span> and the <code>Sleuth2</code> package
<span class="citation">(<span class="citeproc-not-found" data-reference-id="R-Sleuth2"><strong>???</strong></span>)</span>. 
First install and then load that package.</p>
<pre><code>require(Sleuth2)
require(mosaic)
require(tibble)
math &lt;- as.tibble(ex1320)
math
names(math)
favstats(Score ~ Sex+Background, data=math)</code></pre>
<p>4.1. Use the <code>favstats</code> summary to discuss whether the design was balanced or not.</p>
<p>4.2. Make a side-by-side beanplot and
interaction plot array of the results and discuss the relationship between Sex,
Background, and ACT Score.</p>
<p>4.3. Write out the interaction model in
terms of the Greek letters, making sure to define all the terms and don’t
forget the error terms in the model.</p>
<p>4.4. Fit the interaction plot and find
the ANOVA table. For the test you should consider first (the interaction),
write out the hypotheses, report the test statistic, p-value, distribution of
the test statistic under the null, and write a conclusion related to the
results of this test.</p>
<p>4.5. Re-fit the model as an additive
model (why is this reasonable here?) and use <code>Anova</code> to find the Type II sums of
squares ANOVA. Write out the hypothesis for the Background variable, report the
test statistic, p-value, distribution of the test statistic under the null, and
write a conclusion related to the results of this test. Make sure to discuss the scope of inference for this result.</p>
<p>4.6. Use the <code>effects</code> package to make a term-plot from the
additive model from 4.5 and discuss the results. Specifically, discuss what you
can conclude about the average relationship across both sexes, between
Background and average ACT score?</p>
<p>4.7. Make our standard diagnostic plots
and assess the assumptions using these plots. Can you assess independence using
these plots? Discuss this assumption in this situation.</p>
<p>4.8. Use the estimated model
coefficients to determine which of the combinations of levels provides the
highest estimated average score.</p>
<p>As a second example, consider data based on Figure 3 from <span class="citation">Puhan et al. (<a href="#ref-Puhan2006" role="doc-biblioref">2006</a>)</span>, which is
available at <a href="http://www.bmj.com/content/332/7536/266" class="uri">http://www.bmj.com/content/332/7536/266</a>. In this study, the
researchers were interested in whether didgeridoo playing might impact sleep
quality (and therefore daytime sleepiness). They obtained volunteers and they
randomized the subjects to either get a lesson or be placed on a waiting list
for lessons. They constrained the randomization based on the high/low apnoea
and high/low on the Epworth scale of the subjects in their initial observations
to make sure they balanced the types of subjects going into the treatment and
control groups. They measured the subjects’ Epworth value (daytime sleepiness,
higher is more sleepy) initially and after four months, where only the treated
subjects (those who took lessons) had any intervention. We are interested in
whether the mean Epworth scale values changed differently over the four months
in the group that got didgeridoo lessons than it did in the control group (that
got no lessons). Each subject was measured twice in the data set provided that
is available at <a href="http://www.math.montana.edu/courses/s217/documents/epworthdata.csv" class="uri">http://www.math.montana.edu/courses/s217/documents/epworthdata.csv</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(readr)
epworthdata &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/epworthdata.csv&quot;</span>)
epworthdata<span class="op">$</span>Time &lt;-<span class="st"> </span><span class="kw">factor</span>(epworthdata<span class="op">$</span>Time)
<span class="kw">levels</span>(epworthdata<span class="op">$</span>Time) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Pre&quot;</span> , <span class="st">&quot;Post&quot;</span>)
epworthdata<span class="op">$</span>Group &lt;-<span class="st"> </span><span class="kw">factor</span>(epworthdata<span class="op">$</span>Group)
<span class="kw">levels</span>(epworthdata<span class="op">$</span>Group) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Control&quot;</span> , <span class="st">&quot;Didgeridoo&quot;</span>)</code></pre>
<p>4.9. Make an interaction plot array to graphically explore the potential interaction of Time and Group on the Epworth responses.</p>
<p>4.10. Fit the interaction plot and find
the ANOVA table. For the test you should consider first (the interaction),
write out the hypotheses, report the test statistic, p-value, distribution of
the test statistic under the null, and write a conclusion related to the
results of this test.</p>
<p>4.11. Discuss the independence assumption for the previous model. The researchers used an analysis based on matched pairs. Discuss how using ideas from matched pairs might be applicable to the scenario discussed here.</p>
<p>4.12. Refine the model based on the previous test result and continue refining the model as the results might suggest. This should lead to retaining just a single variable. Make an effects plot for this model and discuss this result related to the intent of the original research. If you read the original paper, they did find evidence of an effect of learning to play the didgeridoo (that there was a different change over time in the treated control when compared to the control group) – why might they have gotten a different result (hint: think about the previous question).</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Doolittle1989">
<p>Doolittle, Alan E., and Catherine Welch. 1989. “Gender Differences in Performance on a College-Level Acheivement Test.” <em>ACT Research Report</em>, 89–90.</p>
</div>
<div id="ref-R-faraway">
<p>Faraway, Julian. 2016. <em>Faraway: Functions and Datasets for Books by Julian Faraway</em>. <a href="https://CRAN.R-project.org/package=faraway">https://CRAN.R-project.org/package=faraway</a>.</p>
</div>
<div id="ref-Fox2011">
<p>Fox, John, and Sanford Weisberg. 2011. <em>An R-Companion to Applied Regression, Second Edition</em>. Thousand Oaks, CA: SAGE Publications. <a href="http://socserv.socsci.mcmaster.ca/jfox/Books/Companion">http://socserv.socsci.mcmaster.ca/jfox/Books/Companion</a>.</p>
</div>
<div id="ref-R-car">
<p>Fox, John, Sanford Weisberg, and Brad Price. 2018a. <em>Car: Companion to Applied Regression</em>. <a href="https://CRAN.R-project.org/package=car">https://CRAN.R-project.org/package=car</a>.</p>
</div>
<div id="ref-Lea1995">
<p>Lea, Stephen E. G., Paul Webley, and Catherine M. Walker. 1995. “Psychological Factors in Consumer Debt: Money Management, Economic Socialization, and Credit Use.” <em>Journal of Economic Psychology</em> 16 (4): 681–701.</p>
</div>
<div id="ref-Likert1932">
<p>Likert, Rensis. 1932. “A Technique for the Measurement of Attitudes.” <em>Archives of Psychology</em> 140: 1–55.</p>
</div>
<div id="ref-Puhan2006">
<p>Puhan, Milo A, Alex Suarez, Christian Lo Cascio, Alfred Zahn, Markus Heitz, and Otto Braendli. 2006. “Didgeridoo Playing as Alternative Treatment for Obstructive Sleep Apnoea Syndrome: Randomised Controlled Trial.” <em>BMJ</em> 332 (7536): 266–70. <a href="https://doi.org/10.1136/bmj.38705.470590.55">https://doi.org/10.1136/bmj.38705.470590.55</a>.</p>
</div>
<div id="ref-Ramsey2012">
<p>Ramsey, Fred, and Daniel Schafer. 2012. <em>The Statistical Sleuth: A Course in Methods of Data Analysis</em>. Cengage Learning. <a href="https://books.google.com/books?id=eSlLjA9TwkUC">https://books.google.com/books?id=eSlLjA9TwkUC</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="55">
<li id="fn55"><p>We will use “main effects” to refer to the two
explanatory variables in the additive model even if they are not randomly
assigned to contrast with having those variables interacting in the model.
It is the one place in the book where we use “effects” without worrying about random
assignment.<a href="chapter4.html#fnref55" class="footnote-back">↩</a></p></li>
<li id="fn56"><p>In the standard
ANOVA table,
<span class="math inline">\(\text{SS}_A + \text{SS}_B + \text{SS}_{AB} + \text{SS}_E = \text{SS}_{\text{Total}}\)</span>.
However, to get the tests we really desire when our designs are not balanced, a
slight modification of the SS is used, using what are called Type II sums of
squares and this result doesn’t hold in the output you will see for additive
models. This is discussed further below.<a href="chapter4.html#fnref56" class="footnote-back">↩</a></p></li>
<li id="fn57"><p>The <code>anova</code> results are not wrong, just not what we want.<a href="chapter4.html#fnref57" class="footnote-back">↩</a></p></li>
<li id="fn58"><p>Actually, the tests are only conditional
on other main effects if Type II Sums of Squares are used for an interaction
model.<a href="chapter4.html#fnref58" class="footnote-back">↩</a></p></li>
<li id="fn59"><p>In Multiple Linear Regression models in
Chapter <a href="chapter8.html#chapter8">8</a>, the reasons for this wording will (hopefully)
become clearer.<a href="chapter4.html#fnref59" class="footnote-back">↩</a></p></li>
<li id="fn60"><p>Just so you don’t think
that perfect R code should occur on the first try, we
have all made similarly serious coding mistakes even after accumulating more
than decade of experience with R. It is finding those mistakes (in time) that matters.<a href="chapter4.html#fnref60" class="footnote-back">↩</a></p></li>
<li id="fn61"><p>We switched back to the <code>anova</code> function here as the <code>Anova</code> function only reports <code>Error in Anova.lm(lm(responses ~ dropsf * brand, data = ptR)) :    residual df = 0</code>, which is fine but not as useful for understanding as what <code>anova</code> provides.<a href="chapter4.html#fnref61" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter5.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Greenwood_Book.pdf"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
